# Collective and Distributed Responsibility

![Representation of the process of moral deliberation.](https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/illustrations/deliberation.png)

## The Problem of Many Hands
!!! question 

    How should we assign moral responsibility when large groups of people, organized or unorganized, wrongfully cause some harm?

This is not just an abstract challenge for moral philosophers. It is known as the 'Problem of Many Hands'[^thompson] and affects areas including:

- Anthropogenic Climate Change
- Medical Negligence
- Public Policy and Governance

## Collective Responsibility
One response to the problem of many hands is to ascribe "collective responsibility" to groups of people or organisations.

!!! success "Collective responsibility"

    Collective responsibility, here, is not the same as mechanisms of legal accountability that are used to fine organisations (e.g. limited liability companies).

!!! danger "Important"

    Whether we can ascribe collective responsibility is independent from any practical consequence (e.g. fines, sanctions). Here, we are just interested in whether it makes sense, conceptually, to blame a collective.

![People discussing and collaborating on a project](https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/illustrations/identifying-claims.png)

### Arguments *For* Collective Responsibility
In large-scale data science and AI projects, the distributed structure of roles and responsibilities is necessary for various reasons:

- Individuals have specific forms of expertise, and the delivery of a fully functional AI system requires a plurality of skills. 
- Reuse of datasets is common, and the collection and curation of the original dataset may not have been performed by the software engineer responsible for training a model. 
- Pre-trained models and cloud computing services are increasingly common (e.g. AI as a service, APIs), such that project teams are reliant on third-party infrastructure.

As such, when we ask where responsibility for the behaviour of an AI system lies (e.g. responsibility for biased or discriminatory inferences), it is incredibly difficult to locate it at an individualistic level of abstraction because of the distributed nature of the system's development. 
Rather, it seems best located at the level of a project team or organisation (i.e. collective and distributed responsibility).

!!! question

    If moral praise and blame is only directed at moral agents, does this make companies or organisations moral agents?


Holding a group collectively responsible can have pragmatic benefits (e.g. punishing a group for the misbehaviour of an individual creates motivating incentives for team members to hold each other responsible to avoid future punishment).[^caveat]
However, our intuitions may still lead us to think that only one person was truly *responsible*.

### Arguments *Against* Collective Responsibility 
Moving beyond intuitions, there are different arguments to oppose the notion of collective responsibility. 

Some of the arguments go against the very idea of collective responsibility making sense as a moral concept, while others focus on more pragmatic considerations on the difficulties of ascribing collective responsibility in practice.

Does it make sense conceptually to hold a group itself (as opposed to its individual members) morally responsible?

Some people have argued that it not possible for groups themselves to cause harm in the way that is required in order to ascribe them moral responsibility. The argument can get quite technical, but they general idea behind it is that groups (as opposed to individuals) are simply not the _kinds of agents_ who can be held responsible for their actions.[^sep_cr]

The following quote by philosopher H. D. Lewis sums up a version of this view quite clearly:

> "Value belongs to the individual and it is the individual who is the sole bearer of moral responsibility. No one is morally guilty except in relation to some conduct which he himself considered to be wrong... Collective responsibility is... barbarous."[^lewis48]

On the other hand, arguments against collective responsibility can be based on pragmatic considerations. In particular, some argue that holding groups responsible can have negative consequences in how we place blame on others in ways that can be unfair.

For example, it can be argued that collective responsibility lets individuals off the hook for personal responsibility. 
For instance, consider the phenomena of the 'bystander effect', explained in the following video:

<iframe width="560" height="315" src="https://www.youtube.com/embed/OSsPfbup0ac?start=35" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

The idea is that when we hold a group responsible for an action, this inevitable 'waters-down' any individual responsibility for said action.

Those who wish to argue against collective notions of responsibility, therefore, may wish to appeal to intuitions or point to such empiricial matter.
However, defendants of collective responsibility could respond that the failure is a conceptual issue. 
That is, an inability to adequately and precisely specify particular types of responsibility. 

For instance, in the context of a data science or AI project, while we may not be able to locate responsibility for the overall behaviour, we can identify specific forms of individual responsibility:

- Responsibility for transparent documentation of data provenance
- Responsibility for due diligence when reusing existing artefacts (e.g. datasets, pre-trained models)
- Responsibility for carrying out thorough risk assessments
- Responsibility for organising meaningful forms or stakeholder engagement

!!! question "Some reflexions"

    - What do you think? 
    - Is collective responsibility a coherent concept?
    Or should we make do with structured forms of individual responsibility?

<figure markdown>
  ![Depiction of ladders against a building with some people looking from the inside of the building, some climbing the ladder, and some helping them by firmly holding the ladder.](https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/illustrations/ladders.jpg)
</figure>


## One More Thing: The Replicability Crisis

Philosopher of Science, Sabina Leonelli, has argued that the replicability crisis is evidence of the challenge of locating moral responsibility and professional accountability within large-scale research projects:

> The recent ‘replicability crisis’ in psychology and biomedicine, which many perceive as evidencing an overwhelming lack of research integrity and a failure of peer review, could also be interpreted as illustrating the difficulties in making individuals accountable for their data processing actions within large research networks—which in turn generates problems when attempting to reconstruct, describe and evaluate the methods and assumptions made in any one piece of research.[^leonelli2016]

[^thompson]: Thompson, D. (1980). Moral responsibility and public officials: The problem of many hands. _American Political Science Review,74_(4), 905–916. [https://doi.org/10.2307/1954312](https://doi.org/10.2307/1954312)

[^caveat]: Admittedly, this is a very punitive way of thinking about the reasons people have for acting responsibly and holding each other responsible.
There are many other reasons, such as those grounded in values, that motivate individuals to act responsibly.

[^sep_cr]: Smiley, M. (2022). Collective responsibility. In E. N. Zalta & U. Nodelman (Eds.), *The Stanford encyclopedia of philosophy*. https://plato.stanford.edu/archives/win2022/entries/collective-responsibility/>.

[^lewis48]: Lewis, H. (1948). Collective responsibility. *Philosophy, 23*(84), 3-18.

[^leonelli2016]: Leonelli, S. (2016). Locating ethics in data science: Responsibility and accountability in global and distributed knowledge production systems. *Philosophical transactions of the Royal society A: Mathematical, physical and engineering sciences, 374*(2083).