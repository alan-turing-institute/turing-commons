---
hide:
  - navigation
  - toc
---

# About this Module

<!-- This page should list learning objectives for this module and provide a summary. -->

[...]

<!-- > **Note for Index Page** -->
<!-- > This module is not a technical introduction to Fair ML methods, nor does it attempt to provide an up-to-date overview of the current methods in the field. -->
<!-- > New methods are currently being developed at a rapid pace, and many of these methods are designed to solve problems with specific techniques (e.g. privacy-preserving federated learning to protect interest of vulnerable groups). -->
<!-- > It is not possible, nor desirable, to keep these resources up-to-date with these sorts of developments. -->
<!-- > Rather, we aim to provide clarity on the practical and ethical consequences of fairness in data-driven technologies. -->
<!-- > As such, we discuss those methods (or classes of methods) that are well established and have wide applicability across domains and use cases. -->

<!-- please draft a summary of the module or copy/paste from the pre-existing HackMD file -->

## Learning Objectives

This module has the following learning objectives:

- Objective 1
- Objective 2

## Table of Contents

<div class="grid cards" markdown>

-   :octicons-beaker-16:{ .lg .middle } __What is Fairness?__

    ---

    This section...

    [:octicons-arrow-right-24: Go to module](rri-203-1.md)

-   :fontawesome-solid-arrows-spin:{ .lg .middle } __Sociocultural Fairness__

    ---

    This section...

    [:octicons-arrow-right-24: Go to module](rri-203-2.md)

-   :material-thought-bubble:{ .lg .middle } __Statistical Fairness__

    ---

    This section...

    [:octicons-arrow-right-24: Go to module](rri-203-3.md)

-   :material-chat-processing:{ .lg .middle } __Practical Fairness__

    ---

    This section...

    [:octicons-arrow-right-24: Go to module](rri-203-4.md)

</div>
