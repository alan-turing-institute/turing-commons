
@article{aggarwal2020,
  title = {Introduction to the {{Special Issue}} on {{Intercultural Digital Ethics}}},
  author = {Aggarwal, Nikita},
  year = {2020},
  month = dec,
  journal = {Philosophy \& Technology},
  volume = {33},
  number = {4},
  pages = {547--550},
  issn = {2210-5433, 2210-5441},
  doi = {10.1007/s13347-020-00428-1},
  abstract = {Recent advances in the capability of digital information technologies\textemdash particularly due to advances in artificial intelligence (AI)\textemdash have invigorated the debate on the ethical issues surrounding their use. However, this debate has often been dominated by `Western' ethical perspectives, values and interests, to the exclusion of broader ethical and socio-cultural perspectives. This imbalance carries the risk that digital technologies produce ethical harms and lack social acceptance, when the ethical norms and values designed into these technologies collide with those of the communities in which they are delivered and deployed. This special issue takes a step towards broadening the approach of digital ethics, by bringing together a range of cultural, social and structural perspectives on the ethical issues relating to digital information technology. Importantly, it refreshes and reignites the field of Intercultural Digital Ethics for the age of AI and ubiquitous computing.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/Q694J32I/Aggarwal - 2020 - Introduction to the Special Issue on Intercultural.pdf}
}

@misc{ai2019,
  title = {Reinforcement {{Learning}} Algorithms \textemdash{} an Intuitive Overview},
  author = {AI, SmartLab},
  year = {2019},
  month = feb,
  journal = {Medium},
  abstract = {Author: Robert Moni},
  howpublished = {https://smartlabai.medium.com/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/KINLECZW/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc.html}
}

@article{arnstein1969,
  title = {A {{Ladder Of Citizen Participation}}},
  author = {Arnstein, Sherry R.},
  year = {1969},
  month = jul,
  journal = {Journal of the American Institute of Planners},
  volume = {35},
  number = {4},
  pages = {216--224},
  issn = {0002-8991},
  doi = {10.1080/01944366908977225},
  abstract = {The heated controversy over ``citizen participation,'' ``citizen control'', and ``maximum feasible involvement of the poor,'' has been waged largely in terms of exacerbated rhetoric and misleading euphemisms. To encourage a more enlightened dialogue, a typology of citizen participation is offered using examples from three federal social programs: urban renewal, anti-poverty, and Model Cities. The typology, which is designed to be provocative, is arranged in a ladder pattern with each rung corresponding to the extent of citizens' power in determining the plan and/or program.}
}

@misc{aronson2018,
  title = {A {{Word About Evidence}}: 4. {{Bias}}\textemdash Etymology and Usage},
  shorttitle = {A {{Word About Evidence}}},
  author = {Aronson, Jeff},
  year = {2018},
  journal = {Catalogue of Bias},
  howpublished = {https://catalogofbias.org/2018/04/10/a-word-about-evidence-4-bias-etymology-and-usag/},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/5LNNHN5N/a-word-about-evidence-4-bias-etymology-and-usag.html}
}

@article{ashmore2019,
  title = {Assuring the {{Machine Learning Lifecycle}}: {{Desiderata}}, {{Methods}}, and {{Challenges}}},
  shorttitle = {Assuring the {{Machine Learning Lifecycle}}},
  author = {Ashmore, Rob and Calinescu, Radu and Paterson, Colin},
  year = {2019},
  month = may,
  journal = {arXiv:1905.04223 [cs, stat]},
  eprint = {1905.04223},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  abstract = {Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our paper provides a comprehensive survey of the state-of-the-art in the assurance of ML, i.e. in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the machine learning lifecycle, i.e. of the complex, iterative process that starts with the collection of the data used to train an ML component for a system, and ends with the deployment of that component within the system. The paper begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Software Engineering,Statistics - Machine Learning},
  file = {/Users/cburr/Zotero/storage/9BAJE732/Ashmore et al. - 2019 - Assuring the Machine Learning Lifecycle Desiderat.pdf;/Users/cburr/Zotero/storage/QIH9HG6C/Ashmore et al. - 2019 - Assuring the Machine Learning Lifecycle Desiderat.pdf}
}

@misc{ball2020,
  title = {The Real Story of {{Cambridge Analytica}} and {{Brexit}} | {{The Spectator}}},
  author = {Ball, James},
  year = {2020},
  month = oct,
  abstract = {In July 2018, Elizabeth Denham \textendash{} the woman in charge of enforcing the UK's laws on data protection \textendash{} appeared on the Today programme, and made a stark allegation. 'In 2014 and 2015, the Facebook platform allowed an app\ldots{} that ended up harvesting 87 million profiles of users around the world that was...},
  howpublished = {https://www.spectator.co.uk/article/were-there-any-links-between-cambridge-analytica-russia-and-brexit-},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/3TG38H22/were-there-any-links-between-cambridge-analytica-russia-and-brexit-.html}
}

@article{barnhart1989,
  title = {{{DOE Human Genome Project}}},
  author = {Barnhart, Benjamin},
  year = {1989},
  journal = {Human Genome Quarterly},
  volume = {1},
  number = {1},
  file = {/Users/cburr/Zotero/storage/JU5MNAFY/Vol1No1.pdf}
}

@book{barocas2019,
  title = {Fairness and Machine Learning},
  author = {Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
  year = {2019},
  keywords = {fairness},
  annotation = {This online, free-to-access book is co-authored by some of the world leading experts on fairness and machine learning.  At the time of writing, it is an incomplete work-in-progress with some chapters missing. But don't let that put you off using this resource.  The chapters that are finished are clear, thorough and do an excellent job of syhnthesising the ethical, legal and social issues of fairness with a precise technical introduction to formal measures and techniques.}
}

@book{beauchamp2013,
  title = {Principles of Biomedical Ethics},
  author = {Beauchamp, Tom L and Childress, James F},
  year = {2013},
  edition = {Seventh},
  publisher = {{Oxford University Press}},
  address = {{New York, N.Y.}},
  isbn = {978-0-19-992458-5},
  langid = {english},
  keywords = {Ethics; Medical,Medical ethics}
}

@book{benjamin2019,
  title = {Race after Technology: Abolitionist Tools for the New {{Jim}} Code},
  shorttitle = {Race after Technology},
  author = {Benjamin, Ruha},
  year = {2019},
  publisher = {{Polity}},
  address = {{Medford, MA}},
  isbn = {978-1-5095-2643-7},
  lccn = {HN90.I56},
  keywords = {21st century,African Americans,Digital divide,Information technology,Race relations,Social aspects,Social conditions,SOCIAL SCIENCE / Demography,United States,Whites}
}

@book{bingham2011,
  title = {The Rule of Law},
  author = {Bingham, T. H},
  year = {2011},
  publisher = {{Allen Lane}},
  address = {{London; New York}},
  isbn = {978-0-14-196201-6},
  langid = {english},
  annotation = {OCLC: 793208482}
}

@book{bowker1999,
  title = {Sorting Things out: Classification and Its Consequences},
  author = {Bowker, Geoffrey C. and Star, Susan Leigh},
  year = {1999},
  series = {Inside Technology},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass.}},
  langid = {english}
}

@book{bridgstock1998,
  title = {Science, Technology, and Society: An Introduction},
  shorttitle = {Science, Technology, and Society},
  author = {Bridgstock, Martin},
  year = {1998},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, U.K. ; New York}},
  isbn = {978-0-521-58320-6 978-0-521-58735-8},
  langid = {english},
  lccn = {Q175.5 .S3738 1998},
  keywords = {Science,Science and state,Social aspects,Technology,Technology and state},
  file = {/Users/cburr/Zotero/storage/AEF9P33J/AEF9P33J.pdf}
}

@misc{bronshtein2020,
  title = {Train/{{Test Split}} and {{Cross Validation}} in {{Python}}},
  author = {Bronshtein, Adi},
  year = {2020},
  month = mar,
  journal = {Medium},
  abstract = {Hi everyone! After my last post on linear regression in Python, I thought it would only be natural to write a post about Train/Test Split\ldots},
  howpublished = {https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/7A7E6HKF/train-test-split-and-cross-validation-in-python-80b61beca4b6.html}
}

@inproceedings{buolamwini2018,
  title = {Gender Shades: {{Intersectional}} Accuracy Disparities in Commercial Gender Classification},
  booktitle = {Conference on Fairness, Accountability and Transparency},
  author = {Buolamwini, Joy and Gebru, Timnit},
  year = {2018},
  pages = {77--91},
  organization = {{PMLR}}
}

@article{burr2019,
  title = {Can {{Machines Read}} Our {{Minds}}?},
  author = {Burr, Christopher and Cristianini, Nello},
  year = {2019},
  month = sep,
  journal = {Minds and Machines},
  volume = {29},
  number = {3},
  pages = {461--494},
  issn = {0924-6495, 1572-8641},
  doi = {10.1007/s11023-019-09497-4},
  abstract = {We explore the question of whether machines can infer information about our psychological traits or mental states by observing samples of our behaviour gathered from our online activities. Ongoing technical advances across a range of research communities indicate that machines are now able to access this information, but the extent to which this is possible and the consequent implications have not been well explored. We begin by highlighting the urgency of asking this question, and then explore its conceptual underpinnings, in order to help emphasise the relevant issues. To answer the question, we review a large number of empirical studies, in which samples of behaviour are used to automatically infer a range of psychological constructs, including affect and emotions, aptitudes and skills, attitudes and orientations (e.g. values and sexual orientation), personality, and disorders and conditions (e.g. depression and addiction). We also present a general perspective that can bring these disparate studies together and allow us to think clearly about their philosophical and ethical implications, such as issues related to consent, privacy, and the use of persuasive technologies for controlling human behaviour.},
  copyright = {All rights reserved},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/7929S8WK/Burr and Cristianini - 2019 - Can Machines Read our Minds.pdf;/Users/cburr/Zotero/storage/E4IS9IWE/Burr and Cristianini - 2019 - Can Machines Read our Minds.pdf}
}

@article{burr2021,
  title = {Ethical {{Assurance}}: {{A}} Practical Approach to the Responsible Design, Development, and Deployment of Data-Driven Technologies},
  shorttitle = {Ethical {{Assurance}}},
  author = {Burr, Christopher and Leslie, David},
  year = {2021},
  month = oct,
  journal = {arXiv:2110.05164 [cs]},
  eprint = {2110.05164},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {This article offers several contributions to the interdisciplinary project of responsible research and innovation in data science and AI. First, it provides a critical analysis of current efforts to establish practical mechanisms for algorithmic assessment, which are used to operationalise normative principles, such as sustainability, accountability, transparency, fairness, and explainability, in order to identify limitations and gaps with the current approaches. Second, it provides an accessible introduction to the methodology of argument-based assurance, and explores how it is currently being applied in the development of safety cases for autonomous and intelligent systems. Third, it generalises this method to incorporate wider ethical, social, and legal considerations, in turn establishing a novel version of argument-based assurance that we call 'ethical assurance'. Ethical assurance is presented as a structured means for unifying the myriad practical mechanisms that have been proposed, as it is built upon a process-based form of project governance that supports inclusive and participatory ethical deliberation while also remaining grounded in social and technical realities. Finally, it sets an agenda for ethical assurance, by detailing current challenges, open questions, and next steps, which serve as a springboard to build an active (and interdisciplinary) research programme as well as contribute to ongoing discussions in policy and governance.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society},
  file = {/Users/cburr/Zotero/storage/SF73AM7A/Burr_Leslie_2021_Ethical Assurance.pdf;/Users/cburr/Zotero/storage/RNDYUN3E/2110.html}
}

@article{burton2020,
  title = {A Systematic Review of Algorithm Aversion in Augmented Decision Making},
  author = {Burton, Jason W. and Stein, Mari-Klara and Jensen, Tina Blegind},
  year = {2020},
  month = apr,
  journal = {Journal of Behavioral Decision Making},
  volume = {33},
  number = {2},
  pages = {220--239},
  issn = {0894-3257, 1099-0771},
  doi = {10.1002/bdm.2155},
  abstract = {Despite abundant literature theorizing societal implications of algorithmic decision making, relatively little is known about the conditions that lead to the acceptance or rejection of algorithmically generated insights by individual users of decision aids. More specifically, recent findings of algorithm aversion\textemdash the reluctance of human forecasters to use superior but imperfect algorithms\textemdash raise questions about whether joint humanalgorithm decision making is feasible in practice. In this paper, we systematically review the topic of algorithm aversion as it appears in 61 peer-reviewed articles between 1950 and 2018 and follow its conceptual trail across disciplines. We categorize and report on the proposed causes and solutions of algorithm aversion in five themes: expectations and expertise, decision autonomy, incentivization, cognitive compatibility, and divergent rationalities. Although each of the presented themes addresses distinct features of an algorithmic decision aid, human users of the decision aid, and/or the decision making environment, apparent interdependencies are highlighted. We conclude that resolving algorithm aversion requires an updated research program with an emphasis on theory integration. We provide a number of empirical questions that can be immediately carried forth by the behavioral decision making community.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/RE2XGAC7/Burton et al_2020_A systematic review of algorithm aversion in augmented decision making.pdf}
}

@article{cadwalladr2017,
  title = {The Great {{British Brexit}} Robbery: How Our Democracy Was Hijacked},
  shorttitle = {The Great {{British Brexit}} Robbery},
  author = {Cadwalladr, Carole},
  year = {2017},
  month = may,
  journal = {The Guardian},
  issn = {0261-3077},
  abstract = {A shadowy operation involving big data, billionaire friends of Trump and the disparate forces of the Leave campaign heavily influenced the result of the EU referendum. Is our electoral process still fit for purpose?},
  chapter = {Technology},
  langid = {british},
  keywords = {Article 50,Big data,Brexit,Data protection,Dominic Cummings,European Union,Facebook,Foreign policy,Politics,Technology,UK news},
  file = {/Users/cburr/Zotero/storage/4Y392D4H/the-great-british-brexit-robbery-hijacked-democracy.html}
}

@article{collins2002,
  title = {The {{Third Wave}} of {{Science Studies}}: {{Studies}} of {{Expertise}} and {{Experience}}},
  shorttitle = {The {{Third Wave}} of {{Science Studies}}},
  author = {Collins, H.M. and Evans, Robert},
  year = {2002},
  month = apr,
  journal = {Social Studies of Science},
  volume = {32},
  number = {2},
  pages = {235--296},
  publisher = {{SAGE Publications Ltd}},
  issn = {0306-3127},
  doi = {10.1177/0306312702032002003},
  abstract = {Science studies has shown us why science and technology cannot always solve technical problems in the public domain. In particular, the speed of political decision-making is faster than the speed of scientific consensus formation. A predominant motif over recent years has been the need to extend the domain of technical decision-making beyond the technically qualified \'elite, so as to enhance political legitimacy. We argue, however, that the `Problem of Legitimacy' has been replaced by the `Problem of Extension' - that is, by a tendency to dissolve the boundary between experts and the public so that there are no longer any grounds for limiting the indefinite extension of technical decision-making rights. We argue that a Third Wave of Science Studies - Studies of Expertise and Experience (SEE) - is needed to solve the Problem of Extension. SEE will include a normative theory of expertise, and will disentangle expertise from political rights in technical decision-making. The theory builds categories of expertise, starting with the key distinction between interactive expertise and contributory expertise. A new categorization of types of science is also needed. We illustrate the potential of the approach by re-examining existing case studies, including Brian Wynne's study of Cumbrian sheep farmers. Sometimes the new theory argues for more public involvement, sometimes for less. An Appendix describes existing contributions to the problem of technical decision-making in the public domain.},
  file = {/Users/cburr/Zotero/storage/HDPUXX42/Collins_Evans_2002_The Third Wave of Science Studies.pdf}
}

@article{collins2015,
  title = {Transparent {{Reporting}} of a Multivariable Prediction Model for {{Individual Prognosis Or Diagnosis}} ({{TRIPOD}}): {{The TRIPOD Statement}}},
  shorttitle = {Transparent {{Reporting}} of a Multivariable Prediction Model for {{Individual Prognosis Or Diagnosis}} ({{TRIPOD}})},
  author = {Collins, Gary S. and Reitsma, Johannes B. and Altman, Douglas G. and Moons, Karel G.M.},
  year = {2015},
  month = jan,
  journal = {Annals of Internal Medicine},
  volume = {162},
  number = {1},
  pages = {55},
  issn = {0003-4819},
  doi = {10.7326/M14-0697},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/YG5PS3V6/Collins et al_2015_Transparent Reporting of a multivariable prediction model for Individual.pdf}
}

@misc{community2019,
  title = {The {{Turing Way}}: {{A Handbook}} for {{Reproducible Data Science}}},
  shorttitle = {The {{Turing Way}}},
  author = {Community, The Turing Way and Arnold, Becky and Bowler, Louise and Gibson, Sarah and Herterich, Patricia and Higman, Rosie and Krystalli, Anna and Morley, Alexander and O'Reilly, Martin and Whitaker, Kirstie},
  year = {2019},
  month = mar,
  copyright = {Creative Commons Attribution 4.0 International, Open Access},
  howpublished = {Zenodo},
  keywords = {data management},
  annotation = {This community-managed resource is an impressive display of the power of openness and emergence.  It began as a "lightly-opinionated" guide to reproducible data science, but has since evolved into a diverse set of guidebooks on topics incluidng project design, communication, collaboration, and ethical research. Go for the book and stay for the active and welcoming community.}
}

@misc{diop2019,
  title = {Explainable {{AI}}: {{The}} Data Scientists' New Challenge},
  shorttitle = {Explainable {{AI}}},
  author = {Diop, Mouhamadou-Lamine},
  year = {2019},
  month = aug,
  journal = {Medium},
  abstract = {Authors: Lamine Diop and Jean Cupe},
  howpublished = {https://towardsdatascience.com/explainable-ai-the-data-scientists-new-challenge-f7cac935a5b4},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/UUSUM44M/explainable-ai-the-data-scientists-new-challenge-f7cac935a5b4.html}
}

@misc{duff-brown2017,
  title = {The Shameful Legacy of {{Tuskegee}} Syphilis Study Still Impacts {{African-American}} Men Today},
  author = {{Duff-Brown}, Beth},
  year = {2017},
  journal = {Stanford Health Policy},
  howpublished = {https://healthpolicy.fsi.stanford.edu/news/researchers-and-students-run-pilot-project-oakland-test-whether-tuskegee-syphilis-trial-last},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/A6CC49DM/researchers-and-students-run-pilot-project-oakland-test-whether-tuskegee-syphilis-trial-last.html}
}

@misc{durso2014,
  title = {Human {{Factors}}},
  author = {Durso, Frank T. and Margulieux, Lauren E. and Blickensderfer, Elizabeth L.},
  year = {2014},
  month = nov,
  pages = {9780199828340--0159},
  publisher = {{Oxford University Press}},
  doi = {10.1093/obo/9780199828340-0159},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/XT9Y95H8/Durso et al_2014_Human Factors.pdf}
}

@book{eubanks2018,
  title = {Automating Inequality: {{How}} High-Tech Tools Profile, Police, and Punish the Poor},
  author = {Eubanks, Virginia},
  year = {2018},
  publisher = {{St. Martin's Press}},
  isbn = {1-4668-8596-3}
}

@misc{europeancommission2014,
  type = {Text},
  title = {Responsible Research \& Innovation},
  author = {European Commission},
  year = {2014},
  month = apr,
  journal = {Horizon 2020},
  abstract = {Responsible research \& innovation},
  howpublished = {https://ec.europa.eu/programmes/horizon2020/en/h2020-section/responsible-research-innovation},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/Z7TITN8R/responsible-research-innovation.html}
}

@incollection{evanoff2020,
  title = {Introducing {{Intercultural Ethics}}},
  booktitle = {The {{Cambridge Handbook}} of {{Intercultural Communication}}},
  author = {Evanoff, Richard},
  editor = {Rings, Guido and Rasinger, Sebastian},
  year = {2020},
  month = feb,
  edition = {First},
  pages = {187--202},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781108555067.014},
  isbn = {978-1-108-55506-7 978-1-108-42969-6 978-1-108-45310-3}
}

@book{feyerabend1978,
  title = {Science in a Free Society},
  author = {Feyerabend, Paul},
  year = {1978},
  publisher = {{Schocken Books}}
}

@article{floridi2019,
  title = {A {{Unified Framework}} of {{Five Principles}} for {{AI}} in {{Society}}},
  author = {Floridi, Luciano and Cowls, Josh},
  year = {2019},
  month = jun,
  journal = {Harvard Data Science Review},
  doi = {10.1162/99608f92.8cd550d1},
  abstract = {Artificial Intelligence (AI) is already having a major impact on society. As a result, many organizations have launched a wide range of initiatives to establish ethical principles for the adoption of socially beneficial AI. Unfortunately, the sheer volume of proposed principles threatens to overwhelm and confuse. How might this problem of `principle proliferation' be solved? In this paper, we report the results of a fine-grained analysis of several of the highest-profile sets of ethical principles for AI. We assess whether these principles converge upon a set of agreed-upon principles, or diverge, with significant disagreement over what constitutes `ethical AI.' Our analysis finds a high degree of overlap among the sets of principles we analyze. We then identify an overarching framework consisting of five core principles for ethical AI. Four of them are core principles commonly used in bioethics: beneficence, non-maleficence, autonomy, and justice. On the basis of our comparative analysis, we argue that a new principle is needed in addition: explicability, understood as incorporating both the epistemological sense of intelligibility (as an answer to the question `how does it work?') and in the ethical sense of accountability (as an answer to the question: `who is responsible for the way it works?'). In the ensuing discussion, we note the limitations and assess the implications of this ethical framework for future efforts to create laws, rules, technical standards, and best practices for ethical AI in a wide range of contexts.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/CZZWYA6H/Floridi_Cowls_2019_A Unified Framework of Five Principles for AI in Society.pdf}
}

@article{gigerenzer1991,
  title = {How to {{Make Cognitive Illusions Disappear}}: {{Beyond}} ``{{Heuristics}} and {{Biases}}''},
  shorttitle = {How to {{Make Cognitive Illusions Disappear}}},
  author = {Gigerenzer, Gerd},
  year = {1991},
  month = jan,
  journal = {European Review of Social Psychology},
  volume = {2},
  number = {1},
  pages = {83--115},
  issn = {1046-3283, 1479-277X},
  doi = {10.1080/14792779143000033},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/MUGDPRA4/Gigerenzer_1991_How to Make Cognitive Illusions Disappear.pdf}
}

@article{gigerenzer1996,
  title = {On Narrow Norms and Vague Heuristics: {{A}} Reply to {{Kahneman}} and {{Tversky}}.},
  author = {Gigerenzer, Gerd},
  year = {1996},
  journal = {Psychological Review},
  volume = {103},
  number = {3},
  pages = {592--596},
  doi = {0.1037/0033-295X.103.3.592}
}

@book{hacking1999,
  title = {The Social Construction of What?},
  author = {Hacking, Ian},
  year = {1999},
  edition = {7. print},
  publisher = {{Harvard Univ. Press}},
  address = {{Cambridge, Mass.}},
  isbn = {978-0-674-00412-2 978-0-674-81200-0},
  langid = {english}
}

@article{hardin1968,
  title = {The {{Tragedy}} of the {{Commons}}},
  author = {Hardin, Garrett},
  year = {1968},
  journal = {Science},
  volume = {162},
  number = {3859},
  pages = {1243--1248},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075}
}

@techreport{hawkins2021,
  title = {Guidance on the {{Assurance}} of {{Machine Learning}} in {{Autonomous Systems}}},
  author = {Hawkins, Richard and Paterson, Colin and Picardi, Chiara and Jia, Yan and Calinescu, Radu and Habli, Ibrahim},
  year = {2021},
  month = mar,
  address = {{University of York}},
  institution = {{Assuring Autonomy International Programme (AAIP)}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/9B4RAFVY/Hawkins et al_2021_Guidance on the Assurance of Machine Learning in Autonomous Systems.pdf}
}

@techreport{ico2020,
  title = {Explaining Decisions Made with {{AI}}},
  author = {ICO and Alan Turing Institute},
  year = {2020},
  month = may,
  institution = {{ICO \& Alan Turing Institute}},
  keywords = {explainability},
  annotation = {This co-authored guide was developed by the Alan Turing Institute and the Information Comissioner's Office. It is primarily aimed at developers and project managers, but the best practices that are recommended can also be generalised to other domains.  The guide covers a wide-range of topics, including an introduction to data protection reulation (in UK). It is also split into three parts: 1) The basics of explaining AI 2) Explaining AI in practice 3) What explaining AI means for your organisation}
}

@misc{ico2021,
  title = {Guide to {{Data Protection}}},
  author = {ICO},
  year = {2021},
  month = oct,
  publisher = {{ICO}},
  abstract = {This guide is for data protection officers and others who have day-to-day responsibility for data protection. It is aimed at small and medium-sized organisations, but it may be useful for larger organisations too.},
  howpublished = {https://ico.org.uk/for-organisations/guide-to-data-protection/},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/EFI4BF9T/guide-to-data-protection.html}
}

@article{jasanoff2003,
  title = {Breaking the {{Waves}} in {{Science Studies}}: {{Comment}} on {{H}}.{{M}}. {{Collins}} and {{Robert Evans}}, '{{The Third Wave}} of {{Science Studies}}'},
  shorttitle = {Breaking the {{Waves}} in {{Science Studies}}},
  author = {Jasanoff, Sheila},
  year = {2003},
  journal = {Social Studies of Science},
  volume = {33},
  number = {3},
  pages = {389--400},
  issn = {0306-3127},
  file = {/Users/cburr/Zotero/storage/6PGY6KT5/Jasanoff_2003_Breaking the Waves in Science Studies.pdf}
}

@article{jasanoff2009,
  title = {Containing the {{Atom}}: {{Sociotechnical Imaginaries}} and {{Nuclear Power}} in the {{United States}} and {{South Korea}}},
  shorttitle = {Containing the {{Atom}}},
  author = {Jasanoff, Sheila and Kim, Sang-Hyun},
  year = {2009},
  month = jun,
  journal = {Minerva},
  volume = {47},
  number = {2},
  pages = {119--146},
  issn = {0026-4695, 1573-1871},
  doi = {10.1007/s11024-009-9124-4},
  abstract = {STS research has devoted relatively little attention to the promotion and reception of science and technology by non-scientific actors and institutions. One consequence is that the relationship of science and technology to political power has tended to remain undertheorized. This article aims to fill that gap by introducing the concept of ``sociotechnical imaginaries.'' Through a comparative examination of the development and regulation of nuclear power in the US and South Korea, the article demonstrates the analytic potential of the imaginaries concept. Although nuclear power and nationhood have long been imagined together in both countries, the nature of those imaginations has remained strikingly different. In the US, the state's central move was to present itself as a responsible regulator of a potentially runaway technology that demands effective ``containment.'' In South Korea, the dominant imaginary was of ``atoms for development'' which the state not only imported but incorporated into its scientific, technological and political practices. In turn, these disparate imaginaries have underwritten very different responses to a variety of nuclear shocks and challenges, such as Three Mile Island (TMI), Chernobyl, and the spread of the anti-nuclear movement.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/7DXMK9JE/Jasanoff and Kim - 2009 - Containing the Atom Sociotechnical Imaginaries an.pdf}
}

@article{jobin2019,
  title = {The Global Landscape of {{AI}} Ethics Guidelines},
  author = {Jobin, Anna and Ienca, Marcello and Vayena, Effy},
  year = {2019},
  month = sep,
  journal = {Nature Machine Intelligence},
  volume = {1},
  number = {9},
  pages = {389--399},
  issn = {2522-5839},
  doi = {10.1038/s42256-019-0088-2},
  annotation = {When this article was published in 2019, there was a significant amount of attention and focus on what the term 'ethical AI' meant, both in principle and in practice.  While this article is not the only one that tried to offer some synthesis for the emerging landscape of AI ethics guidelines, it did attempt to do so at a global perspective.  It should be noted that the work assumes a top-down perspective as its starting point for how to characterise the harms and benefits associated with AI. That is, the focus is on how principles can be used to evaluate projects, rather than being lead by actual practices or experiences. This perspective can be valuable, but may be limited without a complementary bottom-up perspective that engages stakeholders in order to identify felt needs and challenges on their own terms.}
}

@article{kahneman1996,
  title = {On the Reality of Cognitive Illusions.},
  author = {Kahneman, Daniel and Tversky, Amos},
  year = {1996},
  journal = {Psychological Review},
  volume = {103},
  number = {3},
  pages = {582--591}
}

@article{kang2018,
  title = {Facebook {{Says Cambridge Analytica Harvested Data}} of {{Up}} to 87 {{Million Users}}},
  author = {Kang, Cecilia and Frenkel, Sheera},
  year = {2018},
  month = apr,
  journal = {The New York Times},
  issn = {0362-4331},
  abstract = {Mr. Zuckerberg, Facebook's chief executive, will appear before multiple congressional committees next week. It is part of the company's efforts to be more open about its work.},
  chapter = {Technology},
  langid = {american},
  keywords = {Cambridge Analytica,Data-Mining and Database Marketing,Facebook Inc,Presidential Election of 2016,Russian Interference in 2016 US Elections and Ties to Trump Associates,Trump; Donald J,United States Politics and Government,Zuckerberg; Mark E},
  file = {/Users/cburr/Zotero/storage/IZ9WFSI5/mark-zuckerberg-testify-congress.html}
}

@article{kosinski2013,
  title = {Private Traits and Attributes Are Predictable from Digital Records of Human Behavior},
  author = {Kosinski, M. and Stillwell, D. and Graepel, T.},
  year = {2013},
  month = apr,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {110},
  number = {15},
  pages = {5802--5805},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1218772110},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/MF2MBLQF/Kosinski et al_2013_Private traits and attributes are predictable from digital records of human.pdf}
}

@book{kuhn1996,
  title = {The Structure of Scientific Revolutions},
  author = {Kuhn, Thomas S.},
  year = {1996},
  edition = {3rd ed},
  publisher = {{University of Chicago Press}},
  address = {{Chicago, IL}},
  isbn = {978-0-226-45807-6 978-0-226-45808-3},
  lccn = {Q175 .K95 1996},
  keywords = {History,Philosophy,Science}
}

@article{larvor2000,
  title = {Review: {{The Social Construction}} of {{What}}?, By {{Ian Hacking}}.},
  author = {Larvor, Brendan},
  year = {2000},
  journal = {Mind},
  volume = {109},
  number = {435},
  pages = {614--618},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/SUPSDZFF/Larvor - 2000 - Review.pdf}
}

@book{latour1986,
  title = {Laboratory Life: The Construction of Scientific Facts},
  shorttitle = {Laboratory Life},
  author = {Latour, Bruno and Woolgar, Steve},
  year = {1986},
  publisher = {{Princeton University Press}},
  address = {{Princeton, N.J}},
  isbn = {978-0-691-02832-3 978-0-691-09418-2},
  lccn = {QH315 .L315 1986},
  keywords = {Biology,Methodology,Research}
}

@article{leslie2020,
  title = {Tackling {{COVID-19}} through {{Responsible AI Innovation}}: {{Five Steps}} in the {{Right Direction}}},
  shorttitle = {Tackling {{COVID-19}} through {{Responsible AI Innovation}}},
  author = {Leslie, David},
  year = {2020},
  month = jun,
  journal = {Harvard Data Science Review},
  doi = {10.1162/99608f92.4bb9d7a7},
  abstract = {Innovations in data science and artificial intelligence/machine learning (AI/ML) have a central role to play in supporting global efforts to combat COVID-19. The versatility of AI/ML technologies enables scientists and technologists to address an impressively broad range of biomedical, epidemiological, and socioeconomic challenges. This wide-reaching scientific capacity, however, also raises a diverse array of ethical challenges. The need for researchers to act quickly and globally in tackling SARS-CoV-2 demands unprecedented practices of open research and responsible data sharing at a time when innovation ecosystems are hobbled by proprietary protectionism, inequality, and a lack of public trust. Moreover, societally impactful interventions like digital contact tracing are raising fears of `surveillance creep' and are challenging widely held commitments to privacy, autonomy, and civil liberties. Prepandemic concerns that data-driven innovations may function to reinforce entrenched dynamics of societal inequity have likewise intensified given the disparate impact of the virus on vulnerable social groups and the life-and-death consequences of biased and discriminatory public health outcomes. To address these concerns, I offer five steps that need to be taken to encourage responsible research and innovation. These provide a practice-based path to responsible AI/ML design and discovery centered on open, accountable, equitable, and democratically governed processes and products. When taken from the start, these steps will not only enhance the capacity of innovators to tackle COVID-19 responsibly, they will, more broadly, help to better equip the data science and AI/ML community to cope with future pandemics and to support a more humane, rational, and just society.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/QII6V7JY/Leslie_2020_Tackling COVID-19 through Responsible AI Innovation.pdf}
}

@article{leslie2021a,
  title = {Artificial Intelligence, Human Rights, Democracy, and the Rule of Law: A Primer},
  shorttitle = {Artificial Intelligence, Human Rights, Democracy, and the Rule of Law},
  author = {Leslie, David and Burr, Christopher and Aitken, Mhairi and Cowls, Josh and Katell, Michael and Briggs, Morgan},
  year = {2021},
  month = mar,
  journal = {arXiv:2104.04147 [cs]},
  eprint = {2104.04147},
  eprinttype = {arxiv},
  primaryclass = {cs},
  doi = {10.5281/zenodo.4639743},
  abstract = {In September 2019, the Council of Europe's Committee of Ministers adopted the terms of reference for the Ad Hoc Committee on Artificial Intelligence (CAHAI). The CAHAI is charged with examining the feasibility and potential elements of a legal framework for the design, development, and deployment of AI systems that accord with Council of Europe standards across the interrelated areas of human rights, democracy, and the rule of law. As a first and necessary step in carrying out this responsibility, the CAHAI's Feasibility Study, adopted by its plenary in December 2020, has explored options for an international legal response that fills existing gaps in legislation and tailors the use of binding and non-binding legal instruments to the specific risks and opportunities presented by AI systems. The Study examines how the fundamental rights and freedoms that are already codified in international human rights law can be used as the basis for such a legal framework. The purpose of this primer is to introduce the main concepts and principles presented in the CAHAI's Feasibility Study for a general, non-technical audience. It also aims to provide some background information on the areas of AI innovation, human rights law, technology policy, and compliance mechanisms covered therein. In keeping with the Council of Europe's commitment to broad multi-stakeholder consultations, outreach, and engagement, this primer has been designed to help facilitate the meaningful and informed participation of an inclusive group of stakeholders as the CAHAI seeks feedback and guidance regarding the essential issues raised by the Feasibility Study.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning},
  file = {/Users/cburr/Zotero/storage/JYV87CI8/Leslie et al_2021_Artificial intelligence, human rights, democracy, and the rule of law.pdf;/Users/cburr/Zotero/storage/G3KPTMQ9/2104.html}
}

@inbook{list2018,
  ids = {list2018a},
  title = {Democratic {{Deliberation}} and {{Social Choice}}: {{A Review}}},
  shorttitle = {Democratic {{Deliberation}} and {{Social Choice}}},
  booktitle = {The {{Oxford Handbook}} of {{Deliberative Democracy}}},
  author = {List, Christian},
  year = {2018},
  month = sep,
  pages = {462--489},
  publisher = {{Oxford University Press}},
  doi = {10.1093/oxfordhb/9780198747369.013.14},
  abstract = {In normative political theory, it is widely accepted that democracy cannot be reduced to voting alone, but that it requires deliberation. In formal social choice theory, by contrast, the study of democracy has focused primarily on the aggregation of individual opinions into collective decisions, typically through voting. While the literature on deliberation has an optimistic flavour, the literature on social choice is more mixed. It is centred around several paradoxes and impossibility results identifying conflicts between different intuitively plausible desiderata. In recent years, there has been a growing dialogue between the two literatures. This paper discusses the connections between them. Important insights are that (i) deliberation can complement aggregation and open up an escape route from some of its negative results; and (ii) the formal models of social choice theory can shed light on some aspects of deliberation, such as the nature of deliberation-induced opinion change.},
  collaborator = {List, Christian},
  isbn = {978-0-19-874736-9},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/DLHAS37H/List - 2018 - Democratic Deliberation and Social Choice A Revie.pdf;/Users/cburr/Zotero/storage/KVLYJGGS/List - 2018 - Democratic Deliberation and Social Choice A Revie.pdf}
}

@article{mcguire2020,
  title = {The Road Ahead in Genetics and Genomics},
  author = {McGuire, Amy L. and Gabriel, Stacey and Tishkoff, Sarah A. and Wonkam, Ambroise and Chakravarti, Aravinda and Furlong, Eileen E. M. and Treutlein, Barbara and Meissner, Alexander and Chang, Howard Y. and {L{\'o}pez-Bigas}, N{\'u}ria and Segal, Eran and Kim, Jin-Soo},
  year = {2020},
  month = oct,
  journal = {Nature Reviews Genetics},
  volume = {21},
  number = {10},
  pages = {581--596},
  issn = {1471-0056, 1471-0064},
  doi = {10.1038/s41576-020-0272-6},
  abstract = {In celebration of the 20th anniversary of Nature Reviews Genetics, we asked 12 leading researchers to reflect on the key challenges and opportunities faced by the field of genetics and genomics. Keeping their particular research area in mind, they take stock of the current state of play and emphasize the work that remains to be done over the next few years so that, ultimately, the benefits of genetic and genomic research can be felt by everyone.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/8KMY2U9J/McGuire et al. - 2020 - The road ahead in genetics and genomics.pdf}
}

@article{merton1973,
  title = {The {{Normative Structure}} of {{Science}}},
  author = {Merton, Robert K},
  year = {1973},
  journal = {The sociology of science: Theoretical and empirical investigations},
  pages = {267--278}
}

@article{mitchell2019,
  title = {Model {{Cards}} for {{Model Reporting}}},
  author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  year = {2019},
  journal = {Proceedings of the Conference on Fairness, Accountability, and Transparency - FAT* '19},
  eprint = {1810.03993},
  eprinttype = {arxiv},
  pages = {220--229},
  doi = {10.1145/3287560.3287596},
  abstract = {Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology, increasing transparency into how well artificial intelligence technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/cburr/Zotero/storage/87JMTGD2/Mitchell et al_2019_Model Cards for Model Reporting.pdf}
}

@article{mittelstadt2019,
  title = {Principles Alone Cannot Guarantee Ethical {{AI}}},
  author = {Mittelstadt, Brent},
  year = {2019},
  month = nov,
  journal = {Nature Machine Intelligence},
  volume = {1},
  number = {11},
  pages = {501--507},
  issn = {2522-5839},
  doi = {10.1038/s42256-019-0114-4},
  abstract = {Artificial intelligence (AI) ethics is now a global topic of discussion in academic and policy circles. At least 84 public\textendash private initiatives have produced statements describing high-level principles, values and other tenets to guide the ethical development, deployment and governance of AI. According to recent meta-analyses, AI ethics has seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics. Despite the initial credibility granted to a principled approach to AI ethics by the connection to principles in medical ethics, there are reasons to be concerned about its future impact on AI development and governance. Significant differences exist between medicine and AI development that suggest a principled approach for the latter may not enjoy success comparable to the former. Compared to medicine, AI development lacks (1) common aims and fiduciary duties, (2) professional history and norms, (3) proven methods to translate principles into practice, and (4) robust legal and professional accountability mechanisms. These differences suggest we should not yet celebrate consensus around high-level principles that hide deep political and normative disagreement.},
  file = {/Users/cburr/Zotero/storage/YJY786MV/Mittelstadt_2019_Principles alone cannot guarantee ethical AI.pdf}
}

@book{molnar2019,
  title = {Interpretable {{Machine Learning}}},
  author = {Molnar, Christoph},
  year = {2019},
  publisher = {{Online}},
  annotation = {Interpretable models are a pre-requsiite for explainable decisions, and this online and free-to-access book summarises a large swathe of the current research on developing more interpretable machine learning.  It begins with an accessible introduction to interpretability, and then builds on this foundation to introduce more advanced techniques.}
}

@book{morozov2013,
  title = {To Save Everything, Click Here: Technology, Solutionism and the Urge to Fix Problems That Don't Exist},
  shorttitle = {To Save Everything, Click Here},
  author = {Morozov, Evgeny},
  year = {2013},
  publisher = {{Allen Lane}},
  address = {{London}},
  isbn = {978-0-241-95769-1 978-1-84614-548-3 978-1-84614-549-0},
  langid = {english}
}

@incollection{muniesa2015,
  title = {Actor-{{Network Theory}}},
  booktitle = {International {{Encyclopedia}} of the {{Social}} \& {{Behavioral Sciences}}},
  author = {Muniesa, Fabian},
  year = {2015},
  pages = {80--84},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-08-097086-8.85001-1},
  isbn = {978-0-08-097087-5},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/WH83528P/Muniesa_2015_Actor-Network Theory.pdf}
}

@techreport{nationalcommission1979,
  title = {The {{Belmont Report}} - {{Ethical Principles}} and {{Guidelines}} for the {{Protection}} of {{Human Subjects}} of {{Research}}},
  author = {National Commission},
  year = {1979},
  month = apr,
  pages = {10},
  address = {{United States}},
  institution = {{The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research}},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/R5BTVNFL/National Commission_1979_The Belmont Report - Ethical Principles and Guidelines for the Protection of.pdf}
}

@misc{nhgri2021,
  title = {Human {{Genome Project FAQ}}},
  author = {NHGRI},
  year = {2021},
  journal = {National Human Genome Research Institute},
  abstract = {Explore frequently asked questions and answers about the Human Genome Project and its impact on the field of genomics.},
  howpublished = {https://www.genome.gov/human-genome-project/Completion-FAQ},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/7Y5NSLDQ/Completion-FAQ.html}
}

@book{noble2018,
  title = {Algorithms of Oppression},
  author = {Noble, Safiya Umoja},
  year = {2018},
  publisher = {{New York University Press}}
}

@article{obermeyer2019,
  title = {Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations},
  author = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  year = {2019},
  month = oct,
  journal = {Science},
  volume = {366},
  number = {6464},
  pages = {447--453},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aax2342},
  file = {/Users/cburr/Zotero/storage/DN5D6YII/Obermeyer et al_2019_Dissecting racial bias in an algorithm used to manage the health of populations.pdf}
}

@article{owen2012,
  title = {Responsible Research and Innovation: {{From}} Science in Society to Science for Society, with Society},
  shorttitle = {Responsible Research and Innovation},
  author = {Owen, R. and Macnaghten, P. and Stilgoe, J.},
  year = {2012},
  month = dec,
  journal = {Science and Public Policy},
  volume = {39},
  number = {6},
  pages = {751--760},
  issn = {0302-3427, 1471-5430},
  doi = {10.1093/scipol/scs093},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/VYHXLDNM/Owen et al_2012_Responsible research and innovation.pdf}
}

@book{owen2013,
  title = {Responsible Innovation},
  editor = {Owen, Richard and Bessant, J. R. and Heintz, Maggy},
  year = {2013},
  publisher = {{Wiley}},
  address = {{Chichester, West Sussex, United Kingdom}},
  isbn = {978-1-118-55140-0 978-1-118-55139-4 978-1-118-55141-7},
  langid = {english},
  keywords = {Environmental aspects,Moral and ethical aspects,New products,Research; Industrial,Technological innovations},
  annotation = {This edited collection approaches the topic of responsibe innovation with a wide-angled lens.  The chapters cover related concepts such as value sensitive design, public engagement and deliberation, and also includes an oft-cited chapter that lays out the framework for responsible innovation that was built upon for the UK's EPSRC AREA framework. Because of the publication date, the collection does not cover modern topics related to machine learning and AI. However, there are still many valuable lessons that can be taken from the collection of chapters.}
}

@article{pinch1984,
  title = {The {{Social Construction}} of {{Facts}} and {{Artefacts}}: Or {{How}} the {{Sociology}} of {{Science}} and the {{Sociology}} of {{Technology}} Might {{Benefit Each Other}}},
  shorttitle = {The {{Social Construction}} of {{Facts}} and {{Artefacts}}},
  author = {Pinch, Trevor J. and Bijker, Wiebe E.},
  year = {1984},
  month = aug,
  journal = {Social Studies of Science},
  volume = {14},
  number = {3},
  pages = {399--441},
  publisher = {{SAGE Publications Ltd}},
  issn = {0306-3127},
  doi = {10.1177/030631284014003004},
  abstract = {The need for an integrated social constructivist approach towards the study of science and technology is outlined. Within such a programme both scientific facts and technological artefacts are to be understood as social constructs. Literature on the sociology of science, the science-technology relationship, and technology studies is reviewed. The empirical programme of relativism within the sociology of scientific knowledge and a recent study of the social construction of technological artefacts are combined to produce the new approach. The concepts of `interpretative flexibility' and `closure mechanism', and the notion of `social group' are developed and illustrated by reference to a study of solar physics and a study of the development of the bicycle. The paper concludes by setting out some of the terrain to be explored in future studies.},
  file = {/Users/cburr/Zotero/storage/JKEM6GIP/Pinch_Bijker_1984_The Social Construction of Facts and Artefacts.pdf}
}

@article{polanyi1962,
  title = {The {{Republic}} of Science: {{Its}} Political and Economic Theory},
  shorttitle = {The {{Republic}} of Science},
  author = {Polanyi, Michael},
  year = {1962},
  journal = {Minerva},
  volume = {1},
  number = {1},
  pages = {54--73},
  issn = {0026-4695, 1573-1871},
  doi = {10.1007/BF01101453},
  langid = {english}
}

@article{post1990,
  title = {The {{Constitutional Concept}} of {{Public Discourse}}: {{Outrageous Opinion}}, {{Democratic Deliberation}}, and {{Hustler Magazine}} v. {{Falwell}}},
  shorttitle = {The {{Constitutional Concept}} of {{Public Discourse}}},
  author = {Post, Robert C.},
  year = {1990},
  journal = {Harvard Law Review},
  volume = {103},
  number = {3},
  pages = {601--686},
  publisher = {{The Harvard Law Review Association}},
  issn = {0017-811X},
  doi = {10.2307/1341344},
  abstract = {Hustler Magazine v. Falwell is the most recent in a long line of first amendment decisions in which the Supreme Court has extended constitutional protection to outrageous or offensive speech. In this article Professor Post analyzes the theory behind this protection. He argues that speech is defined as outrageous by reference to norms of community life. In the culturally heterogeneous environment of the United States, however, first amendment doctrine functions to facilitate communication among communities, so that a common democratic and public opinion may be formed. For this reason first amendment doctrine demarcates a distinct realm of public discourse that is neutral with respect to the norms of specific communities. Professor Post demonstrates how several important themes in the Falwell opinion follow from this separation of public discourse from community values. In particular he contends that the separation illuminates Falwell's rejection of "outrageousness" and "bad motive" as criteria for the regulation of public discourse, as well as its reliance upon the curious and muddy distinction between fact and opinion. Professor Post notes, however, that the constitutional concept of public discourse is inherently unstable, because speech that violates community norms of civility is perceived as irrational and coercive, and hence as incompatible with public deliberation. Thus first amendment doctrine suspends legal enforcement of the very norms that make rational deliberation possible. Professor Post labels this the "paradox of public discourse," and argues that the paradox accounts for the jagged and uneven course of first amendment doctrine. The article concludes with a discussion of the various methods by which the domain of public discourse may be defined.},
  file = {/Users/cburr/Zotero/storage/7U96JWVM/Post_1990_The Constitutional Concept of Public Discourse.pdf}
}

@article{reverby2001,
  title = {More {{Than Fact}} and {{Fiction}}: {{Cultural Memory}} and the {{Tuskegee Syphilis Study}}},
  shorttitle = {More {{Than Fact}} and {{Fiction}}},
  author = {Reverby, Susan M.},
  year = {2001},
  month = sep,
  journal = {The Hastings Center Report},
  volume = {31},
  number = {5},
  pages = {22},
  issn = {00930334},
  doi = {10.2307/3527701},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/NCDCCXKF/Reverby - 2001 - More Than Fact and Fiction Cultural Memory and th.pdf}
}

@incollection{rohracher2015,
  title = {Science and {{Technology Studies}}, {{History}} Of},
  booktitle = {International {{Encyclopedia}} of the {{Social}} \& {{Behavioral Sciences}}},
  author = {Rohracher, Harald},
  year = {2015},
  pages = {200--205},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-08-097086-8.03064-6},
  isbn = {978-0-08-097087-5},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/YJGVEBGQ/Rohracher_2015_Science and Technology Studies, History of.pdf}
}

@misc{roy2021,
  title = {All {{About Missing Data Handling}}},
  author = {Roy, Baijayanta},
  year = {2021},
  month = jun,
  journal = {Medium},
  abstract = {Missing data is a every day problem that a data professional need to deal with. Though there are many articles, blogs, videos already\ldots},
  howpublished = {https://towardsdatascience.com/all-about-missing-data-handling-b94b8b5d2184},
  langid = {english}
}

@techreport{selectcommittee2000,
  title = {Science and {{Society}}},
  author = {Select Committee},
  year = {2000},
  month = feb,
  address = {{UK}},
  institution = {{House of Lords Select Committee on Science and Technology}},
  langid = {english}
}

@article{spence2013,
  title = {Are Antidepressants Overprescribed?},
  author = {Spence, Des and Reid, Ian C},
  year = {2013},
  journal = {BMJ},
  volume = {346},
  pages = {16--17},
  file = {/Users/cburr/Zotero/storage/JPRLJX2Q/Spence_Reid_2013_Are antidepressants overprescribed.pdf}
}

@article{svoboda2020,
  title = {Deep Learning Delivers Early Detection},
  author = {Svoboda, Elizabeth},
  year = {2020},
  journal = {Nature},
  volume = {587},
  number = {S20-22},
  pages = {3},
  doi = {10.1038/d41586-020-03157-9},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/FQUJC4TR/Stolle - Deep learning delivers early detection.pdf}
}

@book{sweenor2020,
  title = {{{ML Ops}}: {{Operationalizing Data Science}}},
  shorttitle = {{{ML Ops}}},
  author = {Sweenor, David and Hillion, Steven and Rope, Dan and Kannabiran, Dev and Hill, Thomas and O'Connell, Michael},
  year = {2020},
  publisher = {{O'Reilly}},
  abstract = {More than half of the analytics and machine learning (ML) models created by organizations today never make it into production. Instead, many of these ML models do nothing more than provide static insights in a slideshow. If they aren't truly operational, these models can't possibly do what you've trained them to do. This report introduces practical concepts to help data scientists and application engineers operationalize ML models to drive real business change. Through lessons based on numerous projects around the world, six experts in data analytics provide an applied four-step approach-Build, Manage, Deploy and Integrate, and Monitor-for creating ML-infused applications within your organization. You'll learn how to: Fulfill data science value by reducing friction throughout ML pipelines and workflows Constantly refine ML models through retraining, periodic tuning, and even complete remodeling to ensure long-term accuracy Design the ML Ops lifecycle to ensure that people-facing models are unbiased, fair, and explainable Operationalize ML models not only for pipeline deployment but also for external business systems that are more complex and less standardized Put the four-step Build, Manage, Deploy and Integrate, and Monitor approach into action.},
  langid = {english}
}

@techreport{theroyalsociety2019,
  title = {Explainable {{AI}}: The Basics},
  author = {The Royal Society},
  year = {2019},
  month = nov,
  pages = {32},
  langid = {english},
  annotation = {This policy report was published by the UK's Royal Society and is one of the shorter documents on this list.  It offers a simple, non-technical introduction and overview to explainable AI, prioritising accessibility over scope.  For those who are keen to engage in the policy impact and implications of RRI in data science and AI, this report would be useful starting point.  The Royal Society has also published other reports on data governance, machine learning and AI: https://royalsociety.org/topics-policy/data-and-ai/artificial-intelligence/}
}

@article{tversky1974,
  title = {Judgment under Uncertainty: {{Heuristics}} and Biases},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1974},
  journal = {Science (New York, N.Y.)},
  volume = {185},
  number = {4157},
  pages = {1124--1131},
  publisher = {{American association for the advancement of science}}
}

@article{tversky1983,
  title = {Extensional versus Intuitive Reasoning: {{The}} Conjunction Fallacy in Probability Judgment.},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1983},
  journal = {Psychological review},
  volume = {90},
  number = {4},
  pages = {293},
  publisher = {{American Psychological Association}}
}

@misc{ukri2021,
  title = {Responsible Innovation},
  author = {UKRI},
  year = {2021},
  howpublished = {https://www.ukri.org/about-us/policies-standards-and-data/good-research-resource-hub/responsible-innovation/},
  langid = {american},
  file = {/Users/cburr/Zotero/storage/QPZLBVSD/responsible-innovation.html}
}

@misc{vincent2021,
  title = {Google Is Poisoning Its Reputation with {{AI}} Researchers},
  author = {Vincent, James},
  year = {2021},
  month = apr,
  journal = {The Verge},
  abstract = {Can Google be trusted to evaluate its own AI?},
  howpublished = {https://www.theverge.com/2021/4/13/22370158/google-ai-ethics-timnit-gebru-margaret-mitchell-firing-reputation},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/9FCHJRTE/google-ai-ethics-timnit-gebru-margaret-mitchell-firing-reputation.html}
}

@book{vonschomberg2011,
  title = {Towards {{Responsible Research}} and {{Innovation}} in the {{Information}} and {{Communication Technologies}} and {{Security Technologies Fields}}},
  author = {Von Schomberg, Ren{\'e}},
  year = {2011},
  publisher = {{Publications Office of the European Union}},
  isbn = {978-92-79-20404-3}
}

@incollection{ward2020,
  title = {An {{Assurance Case Pattern}} for the {{Interpretability}} of {{Machine Learning}} in {{Safety-Critical Systems}}},
  booktitle = {Computer {{Safety}}, {{Reliability}}, and {{Security}}. {{SAFECOMP}} 2020 {{Workshops}}},
  author = {Ward, Francis Rhys and Habli, Ibrahim},
  editor = {Casimiro, Ant{\'o}nio and Ortmeier, Frank and Schoitsch, Erwin and Bitsch, Friedemann and Ferreira, Pedro},
  year = {2020},
  volume = {12235},
  pages = {395--407},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-55583-2_30},
  abstract = {Machine Learning (ML) has the potential to become widespread in safety-critical applications. It is therefore important that we have sufficient confidence in the safe behaviour of the ML-based functionality. One key consideration is whether the ML being used is interpretable. In this paper, we present an argument pattern, i.e. reusable structure, that can be used for justifying the sufficient interpretability of ML within a wider assurance case. The pattern can be used to assess whether the right interpretability method and format are used in the right context (time, setting and audience). This argument structure provides a basis for developing and assessing focused requirements for the interpretability of ML in safety-critical domains.},
  isbn = {978-3-030-55582-5 978-3-030-55583-2},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/R97ET6TT/Ward_Habli_2020_An Assurance Case Pattern for the Interpretability of Machine Learning in.pdf}
}

@article{weaver2018,
  title = {Facebook Scandal: {{I}} Am Being Used as Scapegoat \textendash{} Academic Who Mined Data},
  shorttitle = {Facebook Scandal},
  author = {Weaver, Matthew},
  year = {2018},
  month = mar,
  journal = {The Guardian},
  issn = {0261-3077},
  abstract = {Cambridge University researcher Aleksandr Kogan says he is being unfairly blamed by Facebook and Cambridge Analytica},
  chapter = {UK news},
  langid = {british},
  keywords = {Cambridge Analytica,Facebook,Privacy,Social networking,Technology,UK news,University of Cambridge},
  file = {/Users/cburr/Zotero/storage/AYM857FS/facebook-row-i-am-being-used-as-scapegoat-says-academic-aleksandr-kogan-cambridge-analytica.html}
}

@article{winner1980,
  title = {Do Artifacts Have Politics?},
  author = {Winner, Langdon},
  year = {1980},
  journal = {Daedalus},
  pages = {121--136},
  publisher = {{JSTOR}}
}

@article{wong2005,
  title = {The {{Discovery}} of {{Fluoxetine Hydrochloride}} ({{Prozac}})},
  author = {Wong, David T. and Perry, Kenneth W. and Bymaster, Frank P.},
  year = {2005},
  month = sep,
  journal = {Nature Reviews Drug Discovery},
  volume = {4},
  number = {9},
  pages = {764--774},
  issn = {1474-1776, 1474-1784},
  doi = {10.1038/nrd1821},
  abstract = {In the early 1970s, evidence of the role of serotonin (5-hydroxytryptamine or 5-HT) in depression began to emerge and the hypothesis that enhancing 5-HT neurotransmission would be a viable mechanism to mediate antidepressant response was put forward. On the basis of this hypothesis, efforts to develop agents that inhibit the uptake of 5-HT from the synaptic cleft were initiated. These studies led to the discovery and development of the selective serotoninreuptake inhibitor fluoxetine hydrochloride (Prozac; Eli Lilly), which was approved for the treatment of depression by the US FDA in 1987. Here, we summarize this research and discuss the many challenges that we encountered during the development of fluoxetine hydrochloride, which has now been widely acknowledged as a breakthrough drug for depression.},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/LDCRWDKN/Wong et al_2005_The Discovery of Fluoxetine Hydrochloride (Prozac).pdf}
}

@article{yesley2008,
  title = {What's {{ELSI}} Got to Do with It? {{Bioethics}} and the {{Human Genome Project}}},
  shorttitle = {What's {{ELSI}} Got to Do with It?},
  author = {Yesley, Michael S.},
  year = {2008},
  month = mar,
  journal = {New Genetics and Society},
  volume = {27},
  number = {1},
  pages = {1--6},
  issn = {1463-6778, 1469-9915},
  doi = {10.1080/14636770701843527},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/SNMF3EP7/Yesley - 2008 - What's ELSI got to do with it Bioethics and the H.pdf}
}

@article{zwart2014,
  title = {Adapt or Perish? {{Assessing}} the Recent Shift in the {{European}} Research Funding Arena from `{{ELSA}}' to `{{RRI}}'},
  shorttitle = {Adapt or Perish?},
  author = {Zwart, Hub and Landeweerd, Laurens and {van Rooij}, Arjan},
  year = {2014},
  month = dec,
  journal = {Life Sciences, Society and Policy},
  volume = {10},
  number = {1},
  pages = {11},
  issn = {2195-7819},
  doi = {10.1186/s40504-014-0011-x},
  abstract = {Two decades ago, in 1994, in the context of the 4th EU Framework Programme, ELSA was introduced as a label for developing and funding research into the ethical, legal and social aspects of emerging sciences and technologies. Currently, particularly in the context of EU funding initiatives such as Horizon2020, a new label has been forged, namely Responsible Research and Innovation (RRI). What is implied in this metonymy, this semantic shift? What is so new about RRI in comparison to ELSA? First of all, for both labels, the signifier (S) was introduced in a top-down manner, well before the concept that was signified by it (s) had acquired a clear and stable profile. In other words, the signifier preceded (and helped or helps to shape) the research strategies actually covered by these labels (the precedence of the signifier over the signified: S/s). Moreover, the newness of RRI does not reside in its interactive and anticipatory orientation, as is suggested by authors who introduced the term, but rather in its emphases on social-economic impacts (valorisation, employment and competitiveness).},
  langid = {english},
  file = {/Users/cburr/Zotero/storage/ZWY6FUDC/Zwart et al. - 2014 - Adapt or perish Assessing the recent shift in the.pdf}
}


