# Project Planning

![An illustration of automated facial recognition](https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/illustrations/facial-recognition.png)

In October 2021, the [Financial Times](https://www.ft.com/content/af08fe55-39f3-4894-9b2f-4115732395b9) reported that facial recognition cameras were being used in UK schools to scan the faces of ''thousands of British pupils in school canteens'' to automate the process of taking payment for lunches.
The managing director of CRB Cunninghams—the company that developed the system sold to schools—claimed that ''In a secondary school you have around about a 25-minute period to serve potentially 1,000 pupils. So we need fast throughput at the point of sale.''

!!! question "Question"

    Does this seem like a plausible justification for the design, development, and deployment of an automated facial recognition system? Or, does the use of controversial and possibly biased technology run the risk of normalising invasive surveillance practices?

Addressing questions such as the one above should be one of the first activities in a responsible project lifecycle.
Unfortunately, vested interests often prevent them from being discussed in an open and responsible manner.
The result can be the treatment of data-driven technologies as a ''hammer'' with which to go looking for nails!

To prevent this, it is best to have a clear idea in mind of what the project's goals are at the outset, and what problem is being addressed.
This can help to avoid a myopic focus on a narrow class of technology-based "solutions", and also helps create space for a diversity of approaches—some of which may not require data-driven technology at all.

Project planning, therefore, can comprise a wide variety of tasks, including, but not limited to:

- an assessment of whether developing or using data-driven technology is the right approach given available resources and data, existing technologies and processes already in place, the complexity of the use-contexts involved, and the nature of the policy or social problem that needs to be solved[@leslie2021a];
- a discussion with an *ethics committee* or *internal review board* to help evaluate the ethical credentials of the project;
- an analysis of *user needs* in relation to the prospective model and whether a solution involving the latter provides appropriate affordances in keeping with user needs and related functional desiderata;
- identification and mapping of key stages in the project to support *project governance* and business tasks (e.g. scenario planning);
- an assessment of *resources and capabilities* within a team, which is necessary for identifying any *skills gaps*;
- a contextual assessment of the target domain and of the expectations, norms, and requirements that derive therefrom;
- a *stakeholder impact assessment*, supported by affected people and communities, to identify and evaluate possible harms and benefits associated with the project (e.g. socioeconomic inequalities that may be exacerbated as a result of carrying out the project), to gain social license and public trust, and also feed into the process of problem formulation in the next stage;
- an analysis of *team positionality* to determine the appropriate level and scope of community engagement activities (Leslie et al 2021b);
- wider *impact assessments*—both where required by statute and done voluntarily for transparency and best practice (e.g. equality impact assessments, data protection impact assessments, human rights impact assessment, bias assessment).

This can be a lot to undertake at the outset of a project, but the upfront cost can help offset the large technical and ethical debt that may otherwise accumulate from a failure to anticipate or foresee possible challenges.
