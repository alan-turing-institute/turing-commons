# Understanding RRI

The term 'responsible research and innovation' is most strongly associated with the European Commission's Framework Programmes for Research and Technological Development—a set of funding programmes that support research in the European Union.
Beginning with the seventh framework programme in 2010, and continuing on through Horizon 2020 (FP8), the term 'responsible research and innovation' became increasingly important for the European Commission's policy.

Since then, other national funding bodies have also shown a commitment to RRI.
For example, UKRI's Engineering and Physical Sciences Research Council have developed the AREA framework, which sets out four principles for RRI: Anticipate, Reflect, Engage, and Act (AREA).

In almost all cases, two significant and motivating drivers behind these policies and principles are (a) an awareness of the impact that science and technology can have on society, and (b) an appreciation of the need to include the public in a dialogue about how science and technology should shape society.
The following three case studies help to provide illustrations of these points, while also serving as useful examples that will be returned to in subsequent discussions.

## Case Study 1: Tuskegee Syphilis Study

<figure markdown>
  ![Doctor drawing blood from a patient as part of the Tuskegee Syphilis Study](https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/graphics/tuskegee.jpg){ align="center" }
  <figcaption>Doctor drawing blood from a patient as part of the Tuskegee Syphilis Study (Reprinted from Wikimedia Commons—https://commons.wikimedia.org/wiki/File:Tuskegee-syphilis-study_doctor-injecting-subject.jpg).</figcaption>
</figure>

Starting in 1932, the U.S. Public Health Service ran a study of “untreated syphilis in the male Negro”, which affected almost 400 African-American men with the disease.[@reverby2001]
As we know today, Syphilis can cause many symptoms including sores, blindness, hair loss, stroke, heart failure, and even death if left untreated.
However, aside from the risk that these men were exposed to, a particularly abusive aspect of the study was that it was carried out on _impoverished individuals_, affected by the Great Depression, all while telling them they were being “treated” for their “bad blood”.[@reverby2001]

The study created a massive outcry but, nevertheless, continued for 40 years until 1972.
In this time, syphilis became treatable as a result of the increased availability of penicillin, and funding for the study was withdrawn.
However, as one of the participants states,

!!! quote

    ''The thing that disturbs me now is that they found a cure,'' Shaw told the Baltimore Sun. ''They found penicillin. And they never gave it to us. It vexed me awfully sadly.''[@duffbrown2017]

By the time the study ended, 128 participants had died from syphilis or related complications.
Moreover, 40 of the participants’ spouses had been infected, and 19 children were born with congenital syphilis.
It should be obvious why this case study is infamous and well-rehearsed in courses on research ethics or biomedical ethics.[@beauchamp2013]
However, there are many reasons for the study's continued infamy that have direct relevance to RRI, including the need to continually reflect on the structural biases that exist in society and create forms of racial discrimination that researchers should not ignore.
One specific consideration is the fact that the study directly influenced a landmark event in the ethical importance of informed consent: the 1979 Belmont Report.[@nationalcommission1979]

This report, produced by the US National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research, set out a variety of guidelines for clinical research, including the requirement for participants to have an understanding of the research being conducted, in order to provide informed consent.

!!! quote

    Respect for persons requires that subjects, to the degree that they are capable, be given the opportunity to choose what shall or shall not happen to them. This opportunity is provided when adequate standards for informed consent are satisfied.[@nationalcommission1979]

The conditions that need to be satisfied are,

1. Disclosure of sufficient information
2. Ensuring participant's comprehension
3. Voluntarily providing consent

Neither (1) nor (2) were satisfied in the Tuskegee study, and it would be difficult to argue that (3) was satisfied given the socioeconomic deprivation which affected the participants.

Aside from the historical importance of this study, its inclusion here is also to help highlight why so much significance is placed on the responsible participation of stakeholder and affected users or individuals in present day research and activity.
We will say more about this in the [next section](sts.md).

## Case Study 2: Human Genome Project

<figure markdown>
  ![DNA Double Helix](https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/graphics/genome.jpeg){ align="center" }
  <figcaption>DNA Double Helix</figcaption>
</figure>

The Human Genome Project was proposed in 1986 following a project feasibility workshop in Santa Fe, New Mexico.
At the time, the US Department of Energy's Health and Environmental Research Advisory Committee urged the department

!!! quote

    to commit to a large, long-term, multidisciplinary, technological undertaking to order and sequence the human genome.[@barnhart1989]

Nearly 20 years and 2.7 billion dollars later, on April 14, 2003, the project was formally announced as complete.
The project had been an international effort to identify all of our ~20,500 genes and determine the sequences of nearly 3 billion chemical base pairs make up our DNA.
The scale of the project and the magnitude of the technological accomplishments should be praised in their own rights.
But even more impressive is the continuing impact that this project has had on research projects, collaborative practices, and technological advancements.[@mcguire2020]

Even from the very beginning of the project, it was clear that expanding our knowledge of genetics and genomics would have profound impacts on society—not all of which would be positive.
For example, concerns were voiced about whether the knowledge could be used to further discriminate against certain individuals or sub-groups of the human population, raising the spectre of past injustices caused by the practice of eugenics.[^gattaca]
Therefore, in 1990, the National Human Genome Research Institute founded a program to specifically oversee and study the project's ethical, legal, and social implications, known as the ELSI program.[@nhgri2021]

[^gattaca]: This concern became the centrepiece for the 1997 dystopian sci-fi, Gattaca, which takes its title from the four letters of the nucleobases of DNA.

Writing several years after the completion of the project, the manager of the ELSI program, Michael S. Yesley, offered some remarks that are worth quoting in full.

!!! quote

    The qualifications to do bioethics analysis are straightforward: familiarity with, and ability to analyze, the relevant _facts and values_. No discipline or profession has a monopoly on these skills or should dominate the process. Of the major disciplines engaged in bioethics, philosophy is useful in raising questions and providing rationale, but the actual resolution of bioethics issues – deciding which course of action to take or recommend – generally relies most heavily on factual analysis and seldom on philosophical insight alone. Law sometimes resolves bioethics issues but in most cases establishes only what is _socially permissible_, not what is most desirable, or merely imposes procedural requirements rather than a substantive result. The ethics traditions of medicine and science pervade bioethics and provide much guidance, but these professional perspectives have built-in conflicts that practitioners may not recognize when _balancing the rights and interests of others_. Social science is an obvious source of empirical information about both facts and values, but just as other fields play limited roles in bioethics, social science must be integrated in the broad policymaking process. To be useful in this process, social science must view bioethics policymaking as the goal, not the object, of its study.[@yesley2008] (emphasis added) 

Three things stand out about this quotation.
First, Yesley is acutely aware of the complex relationship between both facts and values, but also between competing value perspectives when analysing and determining what is desirable from scientific research or technological innovation.

Second, as a lawyer, he also has an appreciation of the normative limitations that can be derived from legal precedents, acknowledging that the law tends to establish that which is _socially permissible_ but not what is _most desirable_.
To paraphrase, the law can help create guardrails but is often unable on its own to set the direction of travel.

And, finally, Yesley recognises that reflection on ethical, legal, and social implications counts for little without an ability to influence and shape policy.
This final point is important, as Yesley continues by acknowledging how the model employed by ELSI reflected little consideration of whether it ''would be useful or appropriate to develop public policy that could potentially question the direction of the [Human Genome Project's] scientific research''.
And, furthemore, that the project's scientist-administrators, ''established ELSI simply by earmarking funds from their science budget, and they controlled the content of ELSI by determining the boundaries of the funded research. No one would represent the public interest in the administration of ELSI, which would lack at its core an independent, representative entity to analyze the issues, determine research needs, analyze research results and develop well-supported policy recommendations''.

At first glance, therefore, the 5% of the annual budget of the Human Genome Project that was earmarked for ELSI research seems impressive, and certainly unprecedented in terms of ethical funding.
But Yesley's comments should give us pause to ask how the language of ethics—and indeed, RRI—can be co-opted by commercial, scientific, and political interests, rather than being used to cast a critical perspective on the most pressing questions that face society.
This is all the more important when one recognises how many of the questions raised by the Human Genome Project are also brought up in the context of data ethics and AI ethics, such as the possibility of discriminatory outcomes, or concerns about "ethics-washing" by those with vested interests in the advancement of science and technology.
As we will see in the next section, it is important to ask what social goal is being served by research and innovation, and whether such a goal is desirable as well as permissible.

## Case Study 3: Cambridge Analytica

<figure markdown>
  ![Cambridge Analytica Logo](https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/graphics/cambridge-analytica.png){ align="center" }
  <figcaption>Cambridge Analytica Logo</figcaption>
</figure>

In 2013, three researchers at the University of Cambridge and Microsoft Research published a paper in the Proceedings of the National Academy of Sciences.
The paper was titled, 'Private traits and attributes are predictable from digital records of human behavior', and it provided details of an application (MyPersonality) that allowed Facebook users to participate in a range of psychometric tests, including a personality test, an intelligence test, and a Satisfaction with Life survey.

Following these tests, users were asked if they were happy for their social media profile data to be collected for research purposes.
This included, where available, the various “Likes” of the users; their age, gender, sexual orientation, relationship status, political views, religion, and social network information (e.g. network density); details of the users’ consumption of alcohol, drugs, and cigarettes, and whether their parents stayed together until the user was 21 years old; and also visual inspection of profile pictures, in order to assign ethnicity to a randomly selected subsample of users.

The purpose of gathering this information was to see whether psychological traits could be predicted from social media data.
In short, could the results from the user's psychometric tests be inferred from the data gathered from their social media profiles.
The results were mixed and gave rise to many questions about validity, reliability, and generalisability.[@burr2019]
However, the results or these related questions are not our present concern.

Almost four years after the publication of their research paper, in 2017, Donald Trump was inaugurated as President of the United States and the United Kingdom gave formal notice of its intent to withdraw from the EU following the Brexit referendum.
In an attempt to make sense of these surprising events, a large number of investigative journalists started contacting the three researchers enquiring about their links to a political consulting firm known as Cambridge Analytica.
Despite having never worked with Cambridge Analytica, and refusing their requests, the method the researchers described in their 2013 paper led the firm to work with another Cambridge University researcher to develop their own app.[@weaver2018]
It was later revealed that this app enabled Cambridge Analytica to access the data of up to 87 million Facebook users without their knowledge or permission due to poor data privacy and protection policies on the platform.[@kang2018]
The firm subsequently used this data to develop and sell predictive analytics services to the Trump administration, influencing the outcomes of the US election, and also attempt to court the Leave.EU Brexit campaign.[@ball2020]

The events that surround the Cambridge Analytica data scandal read as though they were plucked from a novel about espionage, information warfare, and PSYOPS, carefully woven together and exposed by the tireless efforts of investigative journalists.[@cadwalladr2017]
Our interest in the case study is, unfortunately, less glamorous.
It can be captured by a single question:

!!! quote

    If you were one of the original researchers, back in 2013, investigating whether social media data could be used to infer otherwise private information about the psychological attitudes and beliefs of users, would you think you were behaving irresponsibly by publishing your research?

In our first activity, we'll reflect on this question and others related to these three case studies.
