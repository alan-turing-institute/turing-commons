
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="An online platform to support open dialogue and reflection about the responsible design, development, and deployment of data-driven technologies.">
      
      
      
        <link rel="canonical" href="https://alan-turing-institute.github.io/turing-commons/skills-tracks/rri/rri-204-3/">
      
      
        <link rel="prev" href="../rri-204-2/">
      
      
        <link rel="next" href="../rri-204-4/">
      
      
      <link rel="icon" href="../../../assets/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.9">
    
    
      
        <title>Model Interpretability - Turing Commons</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
  
  <style>:root{--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M1%203.5c0-.626.292-1.165.7-1.59.406-.422.956-.767%201.579-1.041C4.525.32%206.195%200%208%200s3.475.32%204.722.869c.622.274%201.172.62%201.578%201.04.408.426.7.965.7%201.591v9c0%20.626-.292%201.165-.7%201.59-.406.422-.956.767-1.579%201.041C11.476%2015.68%209.806%2016%208%2016c-1.805%200-3.475-.32-4.721-.869-.623-.274-1.173-.62-1.579-1.04-.408-.426-.7-.965-.7-1.591Zm1.5%200c0%20.133.058.318.282.551.227.237.591.483%201.101.707C4.898%205.205%206.353%205.5%208%205.5s3.101-.295%204.118-.742c.508-.224.873-.471%201.1-.708.224-.232.282-.417.282-.55s-.058-.318-.282-.551c-.227-.237-.591-.483-1.101-.707C11.102%201.795%209.647%201.5%208%201.5s-3.101.295-4.118.742c-.508.224-.873.471-1.1.708-.224.232-.282.417-.282.55m0%204.5c0%20.133.058.318.282.551.227.237.591.483%201.101.707C4.898%209.705%206.353%2010%208%2010s3.101-.295%204.118-.742c.508-.224.873-.471%201.1-.708.224-.232.282-.417.282-.55V5.724c-.241.15-.503.286-.778.407C11.475%206.68%209.805%207%208%207s-3.475-.32-4.721-.869a6%206%200%200%201-.779-.407Zm0%202.225V12.5c0%20.133.058.318.282.55.227.237.592.484%201.1.708%201.016.447%202.471.742%204.118.742s3.102-.295%204.117-.742c.51-.224.874-.47%201.101-.707.224-.233.282-.418.282-.551v-2.275c-.241.15-.503.285-.778.406-1.247.549-2.917.869-4.722.869s-3.475-.32-4.721-.869a6%206%200%200%201-.779-.406%22/%3E%3C/svg%3E');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../../stylesheets/gallery.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="deep-orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model-interpretability" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Turing Commons" class="md-header__button md-logo" aria-label="Turing Commons" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Turing Commons
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Model Interpretability
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="deep-orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="red" data-md-color-accent="red"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/alan-turing-institute/turing-commons" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    alan-turing-institute/turing-commons
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../welcome/" class="md-tabs__link">
        
  
    
  
  Welcome

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
    
  
  Skills Tracks

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../resources/" class="md-tabs__link">
          
  
    
  
  Resources

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../blog/" class="md-tabs__link">
          
  
    
  
  Blog

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Turing Commons" class="md-nav__button md-logo" aria-label="Turing Commons" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    Turing Commons
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/alan-turing-institute/turing-commons" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    alan-turing-institute/turing-commons
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../welcome/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Welcome
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Skills Tracks
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Skills Tracks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Responsible Research and Innovation in Data Science and AI
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_2" id="__nav_3_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Responsible Research and Innovation in Data Science and AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2_2" id="__nav_3_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    What is Responsible Research and Innovation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2_2">
            <span class="md-nav__icon md-icon"></span>
            What is Responsible Research and Innovation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-100-index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About this Module - What is Responsible Research and Innovation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-100-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Understanding Responsibility
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-100-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Collective and Distributed Responsibility
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-100-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Defining Responsible Research and Innovation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-100-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Scope and Horizon of Responsibility
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_3" >
        
          
          <label class="md-nav__link" for="__nav_3_2_3" id="__nav_3_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    The Project Lifecycle Model
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2_3">
            <span class="md-nav__icon md-icon"></span>
            The Project Lifecycle Model
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-101-index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About this Module - The Project Lifecycle
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-101-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is the Project Lifecycle?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-101-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Project Design
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-101-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Development
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-101-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    System Deployment
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_4" checked>
        
          
          <label class="md-nav__link" for="__nav_3_2_4" id="__nav_3_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    The SAFE-D Modules
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_2_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_2_4">
            <span class="md-nav__icon md-icon"></span>
            The SAFE-D Modules
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-200-index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About these Modules - The SAFE-D Principles
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_4_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2_4_2" id="__nav_3_2_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Fairness
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_2_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2_4_2">
            <span class="md-nav__icon md-icon"></span>
            Fairness
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-203-index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About this Module - Fairness
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-203-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is Fairness?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-203-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sociocultural Fairness
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-203-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Statistical Fairness
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-203-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Identifying and Mitigating Bias
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2_4_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_2_4_3" id="__nav_3_2_4_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Explainability
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_2_4_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_2_4_3">
            <span class="md-nav__icon md-icon"></span>
            Explainability
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-204-index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About this Module - Explainability
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-204-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is Explainability?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-204-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Project Transparency
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Model Interpretability
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Model Interpretability
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#what-is-model-interpretability" class="md-nav__link">
    <span class="md-ellipsis">
      What is model interpretability?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="What is model interpretability?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#methods-for-interpreting-models" class="md-nav__link">
    <span class="md-ellipsis">
      Methods for Interpreting Models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#understanding-types-of-interpretability-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding types of interpretability methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understanding types of interpretability methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-intrinsic-versus-post-hoc" class="md-nav__link">
    <span class="md-ellipsis">
      1. Intrinsic versus post hoc
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-model-specific-versus-model-agnostic" class="md-nav__link">
    <span class="md-ellipsis">
      2. Model-specific versus model-agnostic
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-global-versus-local" class="md-nav__link">
    <span class="md-ellipsis">
      3. Global Versus Local
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-outcomes-of-interpretability-methods" class="md-nav__link">
    <span class="md-ellipsis">
      4. Outcomes of Interpretability Methods
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-interpretability-and-responsible-research-and-innovation" class="md-nav__link">
    <span class="md-ellipsis">
      Model Interpretability and Responsible Research and Innovation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Interpretability and Responsible Research and Innovation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-your-data" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding your data
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-explanations" class="md-nav__link">
    <span class="md-ellipsis">
      Building Explanations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#accountability-and-transparency" class="md-nav__link">
    <span class="md-ellipsis">
      Accountability and Transparency
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rri-204-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Situated Explanations
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../ped/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Public Engagement in Data Science and AI
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3" id="__nav_3_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Public Engagement in Data Science and AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../ped/chapter1/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    What is Public Engagement?
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3_2" id="__nav_3_3_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_2">
            <span class="md-nav__icon md-icon"></span>
            What is Public Engagement?
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ped/chapter1/ladder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Climbing the Ladder
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ped/chapter1/goals/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Goals of Public Engagement
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../ped/chapter2/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    The Value(s) of Public Engagement
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3_3" id="__nav_3_3_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_3">
            <span class="md-nav__icon md-icon"></span>
            The Value(s) of Public Engagement
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ped/chapter2/deliberation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deliberative Values
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ped/chapter2/responsible/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Responsible Public Engagement
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../ped/chapter3/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Facilitating Public Engagement
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3_4" id="__nav_3_3_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_4">
            <span class="md-nav__icon md-icon"></span>
            Facilitating Public Engagement
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ped/chapter3/when/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    When should you engage
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ped/chapter3/how/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How should you engage
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../ped/chapter4/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Practical Guidance
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3_5" id="__nav_3_3_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_5">
            <span class="md-nav__icon md-icon"></span>
            Practical Guidance
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ped/chapter4/storytelling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Storytelling with Data
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ped/chapter4/uncertainty/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Communicating Uncertainty
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ped/chapter4/uncertainty-example/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualising Uncertainty
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../ped/chapter5/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Public Trust and Assurance
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3_6" id="__nav_3_3_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_6">
            <span class="md-nav__icon md-icon"></span>
            Public Trust and Assurance
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ped/chapter5/trust/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Public Trust in Science and Technology
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../aeg/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    AI Ethics and Governance
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_4" id="__nav_3_4_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            AI Ethics and Governance
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../aeg/chapter1/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Practical Ethics
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_4_2" id="__nav_3_4_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_2">
            <span class="md-nav__icon md-icon"></span>
            Practical Ethics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter1/metaethics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Metaethics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter1/normative/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Normative Theories
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../aeg/chapter2/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    AI Harms and Values
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_4_3" id="__nav_3_4_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_3">
            <span class="md-nav__icon md-icon"></span>
            AI Harms and Values
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter2/harms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI Harms
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter2/values/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI Values
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../aeg/chapter3/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    AI Sustainability
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_4_4" id="__nav_3_4_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_4">
            <span class="md-nav__icon md-icon"></span>
            AI Sustainability
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter3/engagement/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stakeholder Engagement Process
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter3/impact/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stakeholder Impact Assessment
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../aeg/chapter4/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Fairness & Bias Mitigation, Accountability, and Governance
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_4_5" id="__nav_3_4_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_5">
            <span class="md-nav__icon md-icon"></span>
            Fairness & Bias Mitigation, Accountability, and Governance
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter4/fairness/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Fairness
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter4/aifairness/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI Fairness
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter4/bias/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bias Mitigation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter4/accountability/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accountability
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter4/governance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI Governance
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../aeg/chapter5/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Transparency, Explainability, and CARE and ACT Principles
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_4_6" id="__nav_3_4_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_6">
            <span class="md-nav__icon md-icon"></span>
            Transparency, Explainability, and CARE and ACT Principles
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter5/transparency/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transparency & Explainability
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter5/consider/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Consider Context
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter5/anticipate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Anticipate Impacts
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter5/reflect/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reflect on Purpose, Positionality, and Power
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter5/engage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Engage Inclusively
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../aeg/chapter5/act/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Act Responsibly
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../dj/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Data Justice
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_5" id="__nav_3_5_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            Data Justice
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5_2" >
        
          
          <label class="md-nav__link" for="__nav_3_5_2" id="__nav_3_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction to Data Justice
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction to Data Justice
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj/dj-100-index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to Data Justice
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj/dj-100-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is Data Justice?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj/dj-100-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A brief history of data justice literature
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj/dj-100-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Second-Wave Data Justice Research and Practice
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5_3" >
        
          
          <label class="md-nav__link" for="__nav_3_5_3" id="__nav_3_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    The Six Pillars of Data Justice
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5_3">
            <span class="md-nav__icon md-icon"></span>
            The Six Pillars of Data Justice
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj/dj-101-index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction to the Six Pillars of Data Justice
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj/dj-101-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Power
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj/dj-101-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Equity
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj/dj-101-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Access
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj/dj-101-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Identity
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj/dj-101-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Participation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj/dj-101-6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Knowledge
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5_4" >
        
          
          <label class="md-nav__link" for="__nav_3_5_4" id="__nav_3_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Data Justice in Action
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5_4">
            <span class="md-nav__icon md-icon"></span>
            Data Justice in Action
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj/dj-102-index/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Justice in Action
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj-102-1.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Documentary series
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj-102-2.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introducing Data Justice
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj-102-3.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Uncovering Data Injustice
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dj-102-4.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Mobilising for Data Justice
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../resources/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Resources
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Resources
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../resources/gallery/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gallery
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../resources/bibliographies/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bibliographies
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../resources/case-studies/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Case Studies
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../resources/activities/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Activities
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../blog/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2024/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2024
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2023/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2023
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/archive/2022/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2022
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Categories
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../blog/category/news/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    news
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#what-is-model-interpretability" class="md-nav__link">
    <span class="md-ellipsis">
      What is model interpretability?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="What is model interpretability?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#methods-for-interpreting-models" class="md-nav__link">
    <span class="md-ellipsis">
      Methods for Interpreting Models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#understanding-types-of-interpretability-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding types of interpretability methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understanding types of interpretability methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-intrinsic-versus-post-hoc" class="md-nav__link">
    <span class="md-ellipsis">
      1. Intrinsic versus post hoc
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-model-specific-versus-model-agnostic" class="md-nav__link">
    <span class="md-ellipsis">
      2. Model-specific versus model-agnostic
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-global-versus-local" class="md-nav__link">
    <span class="md-ellipsis">
      3. Global Versus Local
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-outcomes-of-interpretability-methods" class="md-nav__link">
    <span class="md-ellipsis">
      4. Outcomes of Interpretability Methods
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-interpretability-and-responsible-research-and-innovation" class="md-nav__link">
    <span class="md-ellipsis">
      Model Interpretability and Responsible Research and Innovation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Interpretability and Responsible Research and Innovation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-your-data" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding your data
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-explanations" class="md-nav__link">
    <span class="md-ellipsis">
      Building Explanations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#accountability-and-transparency" class="md-nav__link">
    <span class="md-ellipsis">
      Accountability and Transparency
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="model-interpretability">Model Interpretability<a class="headerlink" href="#model-interpretability" title="Permanent link">&para;</a></h1>
<p><a class="glightbox" href="https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/illustrations/ai-squares.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="AI squares" src="https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/illustrations/ai-squares.png" /></a>
Here's a hypothetical scenario that serves as a cautionary tale for the remainder of this section.<sup id="fnref:ambiata"><a class="footnote-ref" href="#fn:ambiata">1</a></sup></p>
<p>A model, trained on a dataset of cars, predicts a car's <code>top speed</code> based on the following three features:</p>
<ol>
<li><code>Colour</code></li>
<li><code>Number of doors</code></li>
<li><code>Convertible</code> (binary value: 'yes' or 'no')</li>
</ol>
<p>The model does very well for cars that are <strong>green</strong>, have <strong>two doors</strong>, and are <strong>convertible</strong>—the model predicts they have very high speeds, and surprisingly has a high level of accuracy.</p>
<p>A team of data analysts are puzzled by this ability and want to employ model interpretability methods to understand how important each of these features are to the prediction and their relative effects.
It turns out that all of the features are important, but none of them are "explaining" why such cars are faster than others.</p>
<p>As you may have guessed, the real reason that the model is accurate in predicting a high top speed in such cases is because most of the cars that are <strong>green</strong>, have <strong>two doors</strong>, and are <strong>convertible</strong> happen to be Lamborghinis, which are known for their high top speeds.</p>
<figure>
<p><a class="glightbox" href="https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/graphics/lamborghini.jpeg" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="A green Lamborghini Huracán Evo Spyder." src="https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/graphics/lamborghini.jpeg" /></a>
  </p>
<figcaption>A green Lamborghini Huracán Evo Spyder.</figcaption>
</figure>
<p>However, none of the features in the model have any causal relationship with the top speed of a car.
Rather, it is the engine (among other things) that is responsible for the top speed of a car.
The other features are what we would call 'confounding variables'—they are not the cause of the top speed, but they are correlated with the cause.</p>
<p>Here is a diagram (reprinted from <a href="https://www.ambiata.com/blog/2021-04-12-xai-part-1/">this article</a>) that illustrates the problem:</p>
<figure>
<p><a class="glightbox" href="https://www.ambiata.com/images/blog/xai-part-1/figure_7_thin1.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="" src="https://www.ambiata.com/images/blog/xai-part-1/figure_7_thin1.png" /></a>
  </p>
<figcaption>Figure 7. The car manufacturer determines the colour, number of doors, whether the car is a convertible or not and the top speed. But in our dataset we only observe the variables in the blue box where there are no arrows between the predictors and top speed.</figcaption>
</figure>
<div class="admonition tip">
<p class="admonition-title"><strong>What is a feature? What is a variable?</strong></p>
<p>For those who are new to machine learning, the difference between 'features' and 'variables' can appear confusing, especially because the two are sometimes used synonymously.
However, the concepts can come apart, and the term 'feature' has a specific meaning that goes beyond the general meaning of 'variable' as employed in statistics more generally.</p>
<p>In short, a feature is some measurable property or characteristic of the data that is used as input for a machine learning algorithm to make predictions or decisions.
In a simple example, the set of features could be the columns in a dataset that represent properties of an object (e.g. <code>number of doors</code>, <code>colour</code>, and <code>convertible</code> in the previous example).
However, features are not always hand selected by ML engineers.
For more complex algorithms, features can be selected or engineered through computational methods, resulting in features that are not readily interpretable by humans due to their lack of semantic meaning.</p>
<p>As such, the variables contained in training datasets, may end being the same as the variables (or, features) that are used as inputs into the model, but this does not have to be the case.
In other cases, many of the original set of variables that may be explored during initial data analysis can be discarded based on their lack of relevance or contribution to model performance.
Therefore, in machine learning, the term 'feature' is used <em>specifically</em> to refer to those input variables that are used for making predictions.</p>
</div>
<p>We won't belabour the well-trodden point about correlation not equalling causation in this section.
However, it is a useful means for drawing attention to the limitation of model interpretability methods to explain causal relationships between the input features and the model's predictions, among other types of explanations (e.g. explanations about data collection issues, or project governance choices).
Moreover, it serves as a gentle reminder about the importance of understanding the limitations of any tool before using it.</p>
<p>In this section, we will explore the more technical aspects of explainability, which rely on the interpretability of the underlying model (including its development and architecture).
This section does not go into the practical details of how to use interpretability methods, but does provide a brief overview of some of the most common methods and tools.
As always, the focus is on the ethical implications of these methods and how they help promote a responsible approach to data science and AI research and innovation.</p>
<h2 id="what-is-model-interpretability">What is model interpretability?<a class="headerlink" href="#what-is-model-interpretability" title="Permanent link">&para;</a></h2>
<p>In the <a href="../rri-204-1/">opening section</a> of this module, we introduced the following definition of interpretability to help distinguish it from explainability:</p>
<blockquote>
<p>Interpretability is the degree to which a human can understand the cause of a decision.<sup id="fnref:miller"><a class="footnote-ref" href="#fn:miller">2</a></sup></p>
</blockquote>
<p>In this section specifically, when we use the term 'interpretability' we will be referring to <strong>model</strong> interpretability, which is the degree to which a human can understand the cause of a model's prediction or behaviour. 
However, it is also appropriate to use the term 'interpretability' to refer to other components of a machine learning system, such as the data or the behaviour of the system itself, which may depend on several models working in concert.</p>
<h3 id="methods-for-interpreting-models">Methods for Interpreting Models<a class="headerlink" href="#methods-for-interpreting-models" title="Permanent link">&para;</a></h3>
<p>There are many methods for interpreting models.
Before we look at a way for categorising them, let's just start with a look at some examples that are loosely representative of the myriad techniques currently available.</p>
<div class="admonition warning">
<p class="admonition-title">Overlaps</p>
<p>When reading the following list, you may think that some of the techniques resemble one another.
You may also find it hard to notice a substantial difference at all. 
If this is the case, do not fret, we will look at a taxonomy shortly that will help bring some conceptual clarity to the miscellany of techniques.</p>
</div>
<ul>
<li>Rule-based models: models that use simple decision rules to arrive at predictions (e.g. decision trees). The rules are often represented in a human-readable format.</li>
<li>Linear models: models where the relationship between the input variables and output variables can be expressed though a simple equation, and the coefficients enable a human to interpret the relative importance of each input variable (e.g. weights in logistic regression models).</li>
<li>Feature importance techniques: techniques that can be used to identify the input variables that are most important for making predictions.
Various techniques exist, such as <em>permutation importance</em> (i.e. repeated and random permutation of the values of each input feature to observe how this affects the model's predictions) or sensitivity analysis (i.e. observing sensitivity of a model to variations in specific features). 
As we will see shortly, feature importance techniques can vary in terms of their scope (i.e. local versus global measures of importance).</li>
<li>Prototypes and criticisms: a technique for explaining how a model classifies instances by first generating 'prototypes' of each class, which are both representative of the class members and, ideally, as differentiable from the other classes as possible.
In contrast, 'criticisms' are instances that do not belong to the class to which they were assigned. 
Both prototypes and criticisms can be informative in understanding where a model is working well and poorly.</li>
<li>Surrogate models: a technique that aims to generate simplified, interpretable models that emulate the predictions of a more complex model (e.g. black box models).
Surrogate model techniques, such as LIME, can help data scientists and machine learning engineers gain insights into how a more complex model operates.</li>
<li>Visualisations: there are many visualisation techniques, familiar to data analysts, that can also help display the outputs of other techniques, such as feature importance, in formats that improve interpretability.</li>
<li>Concept activation vectors: a model-specific technique for neural networks, where a user identifies a concept of interest, and explores how this concept is activated across the neural network by applying several additional techniques (e.g. training supplementary classifiers on a subset of data to predict the behaviour of the underlying neural network). 
Here, 'concept' is a high-level abstraction, which could be made up of many lower-level features in the model (e.g. the concept of 'ears' in a neural network designed to classify images of animals).</li>
<li>Counterfactual explanations: a counterfactual explanation shows how the output of a model (e.g. prediction) would change <em>if</em> the input data were different.</li>
<li>Bayesian networks: the benefit of Bayesian networks is their ability to model the conditional dependencies between input features and output variables. 
Like counterfactual explanations, Bayesian networks can be a useful tool for building causal explanations, when used carefully and with a robust understanding of the data, problem, and the limitations of the tools.</li>
</ul>
<details class="abstract">
<summary><strong>Causal Inference in Machine Learning and AI</strong></summary>
<p>The topic of causal inference in machine learning and AI is a well-studied area of research, but is not within the scope of this section or module.</p>
<p>For more information, see the following resources:</p>
<ul>
<li>Pearl, J. and Mackenzie, D. (2018). The book of why: The new science of cause and effect. <a href="https://www.penguin.co.uk/books/289825/the-book-of-why-by-judea-pearl-and-dana-mackenzie/9780141982410">https://www.penguin.co.uk/books/289825/the-book-of-why-by-judea-pearl-and-dana-mackenzie/9780141982410</a></li>
<li>Sgaier, S. K., Huang, V., and Charles, G. (2020). The case for causal AI. <em>Stanford Social Innovation Review.</em> <a href="https://ssir.org/articles/entry/the_case_for_causal_ai">https://ssir.org/articles/entry/the_case_for_causal_ai</a></li>
<li>Forney, A. and Mueller, S. (2022). Causal inference in AI education: A primer. <em>Journal of Causal Inference.</em> <a href="https://www.degruyter.com/document/doi/10.1515/jci-2021-0048/html">https://www.degruyter.com/document/doi/10.1515/jci-2021-0048/html</a></li>
</ul>
</details>
<h3 id="understanding-types-of-interpretability-methods">Understanding types of interpretability methods<a class="headerlink" href="#understanding-types-of-interpretability-methods" title="Permanent link">&para;</a></h3>
<p>Now that we have seen some specific examples of model interpretability methods, let's try to bring some conceptual order to the landscape.
Christopher Molnar's <a href="https://christophm.github.io/interpretable-ml-book/">excellent book on Interpretable ML</a> provides several useful ways to differentiate model interpretability, which we will take as our starting point:</p>
<ol>
<li>Intrinsic vs Post Hoc</li>
<li>Model-specific vs model-agnostic</li>
<li>Global vs Local</li>
<li>Results of interpretability methods</li>
</ol>
<p>It is important to note that while grouped together into a taxonomy, the four pairs of categories are not necessarily of the same type.
For instance, 'model-specific vs model agnostic' refers to a means for understanding the method by which interpretability is achieved, whereas 'results of interpretability methods' refers to the type of output that is produced by the interpretability method.
The taxonomy is nevertheless highly informative, and so we will now look at each of the elements in further detail.</p>
<h4 id="1-intrinsic-versus-post-hoc">1. Intrinsic versus post hoc<a class="headerlink" href="#1-intrinsic-versus-post-hoc" title="Permanent link">&para;</a></h4>
<p>Intrinsic interpretability is a property of a model that can be measured on a scale from the class of models that are <em>intrinsically</em> interpretable (e.g. simple logistic regression models used for binary classification), through to the class of models that are highly complex and have very low (to no) intrinsic interpretability (e.g. large language models).
For example, the following decision tree would have high levels of intrinsic interpretability because of its simple structure.</p>
<p><a class="glightbox" href="https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/graphics/decision-tree.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="A graphic showing a decision tree where the branches split based on whether a feature exceeds some threshold or not" src="https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/graphics/decision-tree.png" /></a>
<em>A graphic showing a decision tree where the branches split based on whether a feature exceeds some threshold or not.</em></p>
<p>In contrast, post hoc interpretability is a property of the model that is dependant on the application of additional methods or techniques applied after a model's training (hence, post hoc).
For example, random forests—a type of machine learning method known as an 'ensemble method' because it combines the predictions of several simpler models (i.e. decision trees) to predict an outcome (based on the consensus among the different trees within the forest)—have low levels of intrinsic interpretability.
However, post hoc methods (e.g. <a href="https://github.com/marcotcr/lime">LIME</a>) can be applied to help extract interpretations about, say, the importance of specific features, which would otherwise be too complex to extract.</p>
<div class="admonition danger">
<p class="admonition-title"><strong>Clarifications</strong></p>
<p>Two clarifications are worth making:</p>
<ol>
<li>These two types of interpretability are not mutually exclusive. 
Post hoc methods can also be applied to intrinsically interpretable models to improve interpretability.</li>
<li>Intrinsically interpretable models may also depend on the use of techniques to improve interpretability that have been applied <em>prior to training</em> (e.g. feature engineering) for the model to remain <em>intrinsically</em> interpretable. 
As such, they are not strictly speaking 'post hoc' in the sense of being applied after a model has been developed.</li>
</ol>
</div>
<h4 id="2-model-specific-versus-model-agnostic">2. Model-specific versus model-agnostic<a class="headerlink" href="#2-model-specific-versus-model-agnostic" title="Permanent link">&para;</a></h4>
<p>There are a variety of ML models, ranging from simple logistic regression through gradient boosting and to more complex forms of reinforcement learning involving linked neural networks.
The application of interpretability techniques and methods is sometimes constrained by the choice of model.
For instance, integrated gradients for neural networks is a technique for visualising feature importance, as is the case with the following image, where the technique allows the interpreter to see which pixels were important in an image classification task.</p>
<p><a class="glightbox" href="https://www.tensorflow.org/static/tutorials/interpretability/images/IG_fireboat.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="Example of integrated gradients technique showing which parts of an image were important in determining the output of a classification task." src="https://www.tensorflow.org/static/tutorials/interpretability/images/IG_fireboat.png" /></a></p>
<p><em>An example of an integrated gradients technique showing which parts of an image were important in determining the output of a classification task. Reprinted from <a href="https://www.tensorflow.org/tutorials/interpretability/integrated_gradients">TensorFlow</a>.</em></p>
<p>This is an example of a <em>model-specific</em> method, because it requires a calculation to be carried out on specific elements of the underlying neural network, and this method would not apply to other models that have different internal structures.
This is the case even if the objective of <em>determining feature importance</em> is similar to the goal of other methods that enable the interpretation of feature importance (e.g. LIME).</p>
<p>In contrast, model agnostic methods can be used for any model.
As such, they do not utilise any structural information about the model, but typically treat the algorithm as a black box and just focus on understanding which data, inputs, or features were important in the model's prediction.</p>
<p>A common model agnostic method is to compute a partial dependence plot (PDP) to help visualize the relationship between a feature and a model's prediction.
It shows how the model's prediction changes as the value of a feature changes, holding all other features constant.</p>
<div class="admonition danger">
<p class="admonition-title"><strong>Cautionary Tale Redux</strong></p>
<p>Recall the cautionary tale at the start of this section!
Model agnostic methods, such as PDPs, may not help uncover any causal relationships between features and outcomes, as the following example (reprinted from <a href="https://christophm.github.io/interpretable-ml-book/pdp.html">Molnar (2019)</a>) shows:</p>
<p><a class="glightbox" href="https://christophm.github.io/interpretable-ml-book/images/pdp-cervical-2d-1.jpeg" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="A partial dependence plot showing the cancer probability and the interaction of age and number of pregnancies" src="https://christophm.github.io/interpretable-ml-book/images/pdp-cervical-2d-1.jpeg" /></a>
<em>PDP of cancer probability and the interaction of age and number of pregnancies. The plot shows the increase in cancer probability at 45. For ages below 25, women who had 1 or 2 pregnancies have a lower predicted cancer risk, compared with women who had 0 or more than 2 pregnancies. But be careful when drawing conclusions: This might just be a correlation and not causal!</em></p>
</div>
<h4 id="3-global-versus-local">3. Global Versus Local<a class="headerlink" href="#3-global-versus-local" title="Permanent link">&para;</a></h4>
<p>We also have the distinction between local and global scope of interpretability methods.</p>
<p>The example of the partial dependence plot given in the previous section was an example of a global method.
This is because it helps individuals to interpret the relationship between a feature and a model's prediction, independent of any specific observation.
In other words, it focuses on the global interpretability of the model itself.</p>
<p>In contrast, there are also local methods that help interpret why <em>specific</em> predictions were made for a particular observation. Rather than focusing on the model itself, here the focus is on an individual data point or observation.</p>
<p>Both types of interpretability are likely to be useful, but for different circumstances.
For instance, let's assume a user receives a classification that they wish to contest.
Here, local interpretability methods can help the system owner understand why a <em>particular instance</em> (perhaps their data point) was classified as belonging to one bucket, rather than another.
This type of interpretation is likely to be more relevant in forming an explanation that is deemed adequate by the affected user than an explanation that is supported by a global interpretation.</p>
<p>However, if an auditor or procurer is looking to assess the overall robustness and validity of a model as part of an evaluation process, they are more likely to want to understand, say, the overall relationships between features and predictions, which can be generated by global interpretability methods.</p>
<h4 id="4-outcomes-of-interpretability-methods">4. Outcomes of Interpretability Methods<a class="headerlink" href="#4-outcomes-of-interpretability-methods" title="Permanent link">&para;</a></h4>
<p>Finally, Molnar introduces five different outcomes that can be realised through the application of interpretability methods. These are:</p>
<ol>
<li>Feature summary statistics: a variety of metrics that can be used to help quantify the importance of features (e.g. a score that shows the increase in prediction error following permutation to a feature's value), or a pairwise interaction strength between two features.</li>
<li>Feature summary visualisations: a different representational format that can also be used to help illustrate many of the feature summary statistics, in a way that can be more meaningful to a human.</li>
<li>Model internals: values or information used to represent some element in the model's structure, such as its parameter (e.g. weights and biases). 
For intrinsically interpretable models, such as linear regression models, this is how the model is said to be interpretable.</li>
<li>Data points: techniques that return data points as output fall under this category. 
For instance, counterfactual explanations return a data point that is similar to the data point being queried, but where the variation results in a different prediction.</li>
<li>Intrinsically interpretable models: an interpretable model itself constitutes a result of some method, even if the method was to explicitly choose to develop a model that required no additional <em>post hoc</em> methods to be applied.</li>
</ol>
<p>You will notice that the first three types overlap and intersect with these five categories of outcomes.
Again, this is because the taxonomy Molnar provides is not designed to provide a set of categories or types that are both mutually exclusive and jointly exhaustive.
Rather, the taxonomy provides many overlapping and complementary perspectives on the different types of interpretability methods that are available.</p>
<h2 id="model-interpretability-and-responsible-research-and-innovation">Model Interpretability and Responsible Research and Innovation<a class="headerlink" href="#model-interpretability-and-responsible-research-and-innovation" title="Permanent link">&para;</a></h2>
<p><a class="glightbox" href="https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/illustrations/deep-learning.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="Depiction of an ML performing a classificationtask." src="https://raw.githubusercontent.com/alan-turing-institute/turing-commons/main/docs/assets/images/illustrations/deep-learning.png" /></a></p>
<p>By now you will have identified some of the benefits and limitations of model interpretability.
Let's now embed this understanding in the context of responsible research and innovation.</p>
<h3 id="understanding-your-data">Understanding your data<a class="headerlink" href="#understanding-your-data" title="Permanent link">&para;</a></h3>
<p>While the term 'model interpretability methods' would suggest that the focus is on understanding the model itself, by now you will realise this is not always the case.
Rather, model interpretability methods can also be a powerful tool for better understanding your data.
For instance, interpretable ML methods can:</p>
<ul>
<li>Provide insights into which input variables are most important for forming predictions</li>
<li>Help a project team identify errors, biases, or gaps in their dataset (e.g. missing data)</li>
<li>Identify patterns in large, complex, or high-dimensional datasets that would otherwise be too difficult for humans to recognise</li>
</ul>
<p>However, these benefits depend upon a crucial step in the project lifecycle: <em>selecting the right interpretability method</em>.</p>
<p>As the above taxonomy demonstrates, not all methods are created equally and selecting the right tool for the job remains an important maxim.
For example, in many datasets, there will be complex, non-linear relationships between the input variables.
Therefore, a narrow focus on local techniques that help user's interpret the contribution of a single feature to a prediction will not help disclose how, say, a positive weight for one individual feature depends on the existence of a negative weight for some other feature.
As Molnar states:</p>
<blockquote>
<p>The interpretation of a single weight always comes with the footnote that the other input features remain at the same value, which is not the case with many real applications. A linear model that predicts the value of a house, that takes into account both the size of the house and the number of rooms, can have a negative weight for the room feature. It can happen because there is already the highly correlated house size feature. In a market where people prefer larger rooms, a house with fewer rooms could be worth more than a house with more rooms if both have the same size. The weights only make sense in the context of the other features in the model.<sup id="fnref:molnar2022"><a class="footnote-ref" href="#fn:molnar2022">3</a></sup></p>
</blockquote>
<p>This is why the other sections of this module emphasise the importance of a broader awareness of the project lifecycle and the sociocultural context in which the project operates as a crucial means for situating explanations (more on this in the <a href="../rri-204-4/">next section</a>).</p>
<h2 id="building-explanations">Building Explanations<a class="headerlink" href="#building-explanations" title="Permanent link">&para;</a></h2>
<p>As we will see in the <a href="../rri-204-4/">next section</a>, multiple explanations for a system's behaviour may be required, depending on the recipient of the explanation.
Therefore, in contrast to the above points about choosing the right tool for the job, here the plurality of methods can (in some cases) be a benefit.</p>
<p>For instance, <a href="#methods-for-interpreting-models">concept activation vectors</a> may be very useful for a team of ML engineers who are communicating results to another team of ML engineers working in a separate research institution.
However, if the original team decide to do public engagement and outreach they may need to rely on simpler forms of feature importance, surrogate models, or visualisations to help generate an accessible explanation.</p>
<p>Therefore, while the maxim, 'choose the right tool for the job' still applies, it is also important to recognise that there may be multiple tools required for different explanatory purposes.</p>
<p>Here again, we see a major difference between our use of the terms 'interpretability' and 'explainability'.
Whereas we reserve the concept of interpretability for the methods and techniques that are used to understand the inner workings of a model (or system), explainability has a broader scope and refers to any process or mechanism across the whole project lifecycle that supports communication and reason-giving between project team members and stakeholders.</p>
<h2 id="accountability-and-transparency">Accountability and Transparency<a class="headerlink" href="#accountability-and-transparency" title="Permanent link">&para;</a></h2>
<p>Consider the following question.</p>
<div class="admonition question question">
<p class="admonition-title">Question</p>
<p>Why would a stakeholder or user request an explanation for a model's behaviour or the outcomes of an AI system?</p>
</div>
<p>Perhaps they're just interested and want to understand how different types of machine learning models work.
But aside from curiosity and education, there are several other important reasons why stakeholders and users may request an explanation. These include:</p>
<ul>
<li><strong>Compliance</strong>: stakeholders may need to demonstrate that their AI system is compliant with a particular regulation or standard before adopting it in a production environment.</li>
<li><strong>Bias detection</strong>: groups that are under-represented in a dataset may be at a greater risk of being misclassified by a model. 
Therefore, understanding how a model makes predictions can help stakeholders (and team members) carry out bias detection and mitigation tasks, as a broader part of equality impact assessments.</li>
<li><strong>Risk management and redress</strong>: regulators have a duty to protect the public from various types of harm. 
Therefore, model interpretability methods can play an important role in the broader mechanisms of project transparency, which can a) feed into risk management activities, and b) be used retrospectively if some harm occurs and redress for the (possibly unintended) harm is required.</li>
</ul>
<p>These non-exhaustive examples demonstrate how model interpretability methods also feed into broader objectives of responsible research and innovation, such as accountability and transparency.
We cover these topics in more detail in a <del><a href="rri-202-index.md">separate module</a></del> (Note: this module is coming soon).</p>
<p>Now, let us turn to the final section of this module to explore how we can bring all of this knowledge together to help us build (situated) explanations.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:ambiata">
<p>The scenario is adapted and summarised from the same case presented in <a href="https://www.ambiata.com/blog/2021-04-12-xai-part-1/">this article</a>.&#160;<a class="footnote-backref" href="#fnref:ambiata" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:miller">
<p>Miller, T. (2019). Explanation in artificial intelligence: Insights from the social sciences. <em>Artificial intelligence, 267</em>, p. 1-38. <a href="https://doi.org/10.1016/j.artint.2018.07.007">https://doi.org/10.1016/j.artint.2018.07.007</a>&#160;<a class="footnote-backref" href="#fnref:miller" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:molnar2022">
<p>Molnar, C. (2022). Interpretable Machine Learning. A Guide for Making Black Box Models Explainable. <a href="https://christophm.github.io/interpretable-ml-book/scope-of-interpretability.html">https://christophm.github.io/interpretable-ml-book/scope-of-interpretability.html</a>&#160;<a class="footnote-backref" href="#fnref:molnar2022" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
</ol>
</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../rri-204-2/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Project Transparency">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Project Transparency
              </div>
            </div>
          </a>
        
        
          
          <a href="../rri-204-4/" class="md-footer__link md-footer__link--next" aria-label="Next: Situated Explanations">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Situated Explanations
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 Alan Turing Institute
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "navigation.indexes", "navigation.footer", "navigation.instant", "navigation.sections", "navigation.path", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../../../javascripts/tablesort.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>