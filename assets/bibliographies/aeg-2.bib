@article{adams-prassl2022,
  title = {Directly {{Discriminatory Algorithms}}},
  author = {Adams-Prassl, Jeremias and Binns, Reuben and Kelly-Lyth, Aislinn},
  year = {2022},
  month = aug,
  journal = {The Modern Law Review},
  pages = {1468-2230.12759},
  issn = {0026-7961, 1468-2230},
  doi = {10.1111/1468-2230.12759},
  urldate = {2022-11-22},
  langid = {english},
  file = {/Users/cfischer/Zotero/storage/5PXKGMVU/Adams‚ÄêPrassl et al. - 2022 - Directly Discriminatory Algorithms.pdf}
}

@article{ahmed2020,
  title = {The {{De-democratization}} of {{AI}}: {{Deep Learning}} and the {{Compute Divide}} in {{Artificial Intelligence Research}}},
  shorttitle = {The {{De-democratization}} of {{AI}}},
  author = {Ahmed, Nur and Wahed, Muntasir},
  year = {2020},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2010.15581},
  urldate = {2022-11-20},
  abstract = {Increasingly, modern Artificial Intelligence (AI) research has become more computationally intensive. However, a growing concern is that due to unequal access to computing power, only certain firms and elite universities have advantages in modern AI research. Using a novel dataset of 171394 papers from 57 prestigious computer science conferences, we document that firms, in particular, large technology firms and elite universities have increased participation in major AI conferences since deep learning's unanticipated rise in 2012. The effect is concentrated among elite universities, which are ranked 1-50 in the QS World University Rankings. Further, we find two strategies through which firms increased their presence in AI research: first, they have increased firm-only publications; and second, firms are collaborating primarily with elite universities. Consequently, this increased presence of firms and elite universities in AI research has crowded out mid-tier (QS ranked 201-300) and lower-tier (QS ranked 301-500) universities. To provide causal evidence that deep learning's unanticipated rise resulted in this divergence, we leverage the generalized synthetic control method, a data-driven counterfactual estimator. Using machine learning based text analysis methods, we provide additional evidence that the divergence between these two groups - large firms and non-elite universities - is driven by access to computing power or compute, which we term as the "compute divide". This compute divide between large firms and non-elite universities increases concerns around bias and fairness within AI technology, and presents an obstacle towards "democratizing" AI. These results suggest that a lack of access to specialized equipment such as compute can de-democratize knowledge production.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Computers and Society (cs.CY),FOS: Computer and information sciences,Machine Learning (cs.LG)}
}

@article{arnstein1969a,
  title = {A {{Ladder Of Citizen Participation}}},
  author = {Arnstein, Sherry R.},
  year = {1969},
  month = jul,
  journal = {Journal of the American Institute of Planners},
  volume = {35},
  number = {4},
  pages = {216--224},
  issn = {0002-8991},
  doi = {10.1080/01944366908977225},
  urldate = {2022-11-23},
  langid = {english}
}

@book{audard2014,
  title = {John {{Rawls}}},
  author = {Audard, Catherine},
  year = {2014},
  month = dec,
  edition = {Zeroth},
  publisher = {{Routledge}},
  doi = {10.4324/9781315712109},
  urldate = {2022-11-21},
  isbn = {978-1-317-49394-5},
  langid = {english}
}

@article{barocas2016a,
  title = {Big {{Data}}'s {{Disparate Impact}}},
  author = {Barocas, Solon and Selbst, Andrew D.},
  year = {2016},
  journal = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.2477899},
  urldate = {2022-11-21},
  langid = {english}
}

@article{bbc2021,
  title = {Covid: {{South Africa}} 'punished' for Detecting New {{Omicron}} Variant},
  author = {BBC},
  year = {2021},
  month = nov
}

@article{bender2018,
  title = {Data {{Statements}} for {{Natural Language Processing}}: {{Toward Mitigating System Bias}} and {{Enabling Better Science}}},
  shorttitle = {Data {{Statements}} for {{Natural Language Processing}}},
  author = {Bender, Emily M. and Friedman, Batya},
  year = {2018},
  month = dec,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {6},
  pages = {587--604},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00041},
  urldate = {2022-11-23},
  abstract = {In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists, in both research and development. Through the adoption and widespread use of data statements, the field can begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of technology for other populations. We present a form that data statements can take and explore the implications of adopting them as part of regular practice. We argue that data statements will help alleviate issues related to exclusion and bias in language technology, lead to better precision in claims about how natural language processing research can generalize and thus better engineering results, protect companies from public embarrassment, and ultimately lead to language technology that meets its users in their own preferred linguistic style and furthermore does not misrepresent them to others.},
  langid = {english},
  file = {/Users/cfischer/Zotero/storage/C4TAAH3A/Bender and Friedman - 2018 - Data Statements for Natural Language Processing T.pdf}
}

@article{bezuidenhout2017,
  title = {Beyond the Digital Divide: {{Towards}} a Situated Approach to Open Data},
  shorttitle = {Beyond the Digital Divide},
  author = {Bezuidenhout, Louise M. and Leonelli, Sabina and Kelly, Ann H. and Rappert, Brian},
  year = {2017},
  month = aug,
  journal = {Science and Public Policy},
  volume = {44},
  number = {4},
  pages = {464--475},
  issn = {0302-3427, 1471-5430},
  doi = {10.1093/scipol/scw036},
  urldate = {2022-11-20},
  langid = {english},
  file = {/Users/cfischer/Zotero/storage/S8KJVMB6/Bezuidenhout et al. - 2017 - Beyond the digital divide Towards a situated appr.pdf}
}

@article{binns2017,
  title = {Fairness in {{Machine Learning}}: {{Lessons}} from {{Political Philosophy}}},
  shorttitle = {Fairness in {{Machine Learning}}},
  author = {Binns, Reuben},
  year = {2017},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1712.03586},
  urldate = {2022-11-21},
  abstract = {What does it mean for a machine learning model to be `fair', in terms which can be operationalised? Should fairness consist of ensuring everyone has an equal probability of obtaining some benefit, or should we aim instead to minimise the harms to the least advantaged? Can the relevant ideal be determined by reference to some alternative state of affairs in which a particular social pattern of discrimination does not exist? Various definitions proposed in recent literature make different assumptions about what terms like discrimination and fairness mean and how they can be defined in mathematical terms. Questions of discrimination, egalitarianism and justice are of significant interest to moral and political philosophers, who have expended significant efforts in formalising and defending these central concepts. It is therefore unsurprising that attempts to formalise `fairness' in machine learning contain echoes of these old philosophical debates. This paper draws on existing work in moral and political philosophy in order to elucidate emerging debates about fair machine learning.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Computers and Society (cs.CY),FOS: Computer and information sciences}
}

@article{bourke2014,
  title = {Positionality: {{Reflecting}} on the {{Research Process}}},
  author = {Bourke, Brian},
  year = {2014},
  journal = {The Qualitative Report},
  volume = {19},
  number = {33},
  pages = {1--9}
}

@incollection{carozza2013,
  title = {Human {{Dignity}}},
  booktitle = {The {{Oxford Handbook}} of {{International Human Rights Law}}},
  author = {Carozza, Paolo G.},
  editor = {Shelton, Dinah},
  year = {2013},
  month = dec,
  edition = {First},
  pages = {345--359},
  publisher = {{Oxford University Press}},
  doi = {10.1093/law/9780199640133.003.0015},
  urldate = {2022-11-22},
  abstract = {Abstract             This article examines the issue of human dignity in relation to human rights. It analyses the functions and principle of human dignity and its use in the Universal Declaration of Human Rights and other international instruments. It suggests that human dignity seems to help justify expansive interpretations of human rights and strengthens the centrality and importance of the right in question and limiting possible exceptions or limitations to that right. This article also contends that the difficulty of reaching greater consensus on the meaning and implications of human dignity in international human rights law may be attributed to the fact that it refers to both a foundational premise of human rights and to a principle that affect interpretation and application of specific human rights.},
  isbn = {978-0-19-964013-3 978-0-19-175667-2},
  langid = {english}
}

@book{carr2017,
  title = {On {{Fairness}}},
  author = {Carr, Craig L.},
  year = {2017},
  month = nov,
  edition = {First},
  publisher = {{Routledge}},
  doi = {10.4324/9781315199993},
  urldate = {2022-11-21},
  isbn = {978-1-315-19999-3},
  langid = {english}
}

@book{clifford2013,
  title = {Political {{Genealogy After Foucault}}},
  author = {Clifford, Michael},
  year = {2013},
  month = jan,
  edition = {Zeroth},
  publisher = {{Routledge}},
  doi = {10.4324/9780203903100},
  urldate = {2022-11-22},
  isbn = {978-1-135-95657-8},
  langid = {english}
}

@book{custers2013,
  title = {Discrimination and Privacy in the Information Society: Data Mining and Profiling in Large Databases},
  shorttitle = {Discrimination and Privacy in the Information Society},
  author = {Custers, Bart Herman Maria and Custers, Bart},
  year = {2013},
  series = {Studies in Applied Philosophy, Epistemology and Rational Ethics},
  number = {3},
  publisher = {{Springer}},
  address = {{Berlin New York}},
  isbn = {978-3-642-30487-3},
  langid = {english},
  lccn = {006.312}
}

@article{dastinjeffrey,
  title = {Amazon Scraps Secret {{AI}} Recruiting Tool That Showed Bias against Women},
  author = {Dastin, Jeffrey}
}

@article{dworkin2000,
  title = {Affirmative {{Action}}: {{Is It Fair}}?},
  shorttitle = {Affirmative {{Action}}},
  author = {Dworkin, Ronald},
  year = 2000,
  journal = {The Journal of Blacks in Higher Education},
  number = {28},
  eprint = {2678715},
  eprinttype = {jstor},
  pages = {79},
  issn = {10773711},
  doi = {10.2307/2678715},
  urldate = {2022-11-22}
}

@book{eidelson2015,
  title = {Discrimination and Disrespect},
  author = {Eidelson, Benjamin},
  year = {2015},
  publisher = {{Oxford University Press}},
  address = {{Oxford}},
  abstract = {What makes something discrimination, and why (and when) are acts of discrimination wrong? Benjamin Eidelson develops systematic answers to these two questions. He argues that what makes some cases of discrimination intrinsically wrongful is that they manifest an attitude of disrespect for the personhood of those who are disfavoured},
  isbn = {978-0-19-104707-7},
  langid = {english},
  annotation = {OCLC: 920859219}
}

@article{friedman1996,
  title = {Bias in Computer Systems},
  author = {Friedman, Batya and Nissenbaum, Helen},
  year = {1996},
  month = jul,
  journal = {ACM Transactions on Information Systems},
  volume = {14},
  number = {3},
  pages = {330--347},
  issn = {1046-8188, 1558-2868},
  doi = {10.1145/230538.230561},
  urldate = {2022-11-21},
  abstract = {From an analysis of actual cases, three categories of bias in computer systems have been developed: preexisting, technical, and emergent. Preexisting bias has its roots in social institutions, practices, and attitudes. Technical bias arises from technical constraints of considerations. Emergent bias arises in a context of use. Although others have pointed to bias inparticular computer systems and have noted the general problem, we know of no comparable work that examines this phenomenon comprehensively and which offers a framework for understanding and remedying it. We conclude by suggesting that freedom from bias should by counted amoung the select set of criteria\textemdash including reliability, accuracy, and efficiency\textemdash according to which the quality of systems in use in society should be judged.},
  langid = {english}
}

@article{gebru2021,
  title = {Datasheets for Datasets},
  author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Iii, Hal Daum{\'e} and Crawford, Kate},
  year = {2021},
  month = dec,
  journal = {Communications of the ACM},
  volume = {64},
  number = {12},
  pages = {86--92},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3458723},
  urldate = {2022-11-23},
  abstract = {Documentation to facilitate communication between dataset creators and consumers.},
  langid = {english}
}

@article{giovanola2022,
  title = {Weapons of Moral Construction? {{On}} the Value of Fairness in Algorithmic Decision-Making},
  shorttitle = {Weapons of Moral Construction?},
  author = {Giovanola, Benedetta and Tiribelli, Simona},
  year = {2022},
  month = mar,
  journal = {Ethics and Information Technology},
  volume = {24},
  number = {1},
  pages = {3},
  issn = {1388-1957, 1572-8439},
  doi = {10.1007/s10676-022-09622-5},
  urldate = {2022-11-22},
  langid = {english}
}

@incollection{hajian2013,
  title = {Direct and {{Indirect Discrimination Prevention Methods}}},
  booktitle = {Discrimination and {{Privacy}} in the {{Information Society}}},
  author = {Hajian, Sara and {Domingo-Ferrer}, Josep},
  editor = {Custers, Bart and Calders, Toon and Schermer, Bart and Zarsky, Tal},
  year = {2013},
  volume = {3},
  pages = {241--254},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-30487-3_13},
  urldate = {2022-11-21},
  isbn = {978-3-642-30486-6 978-3-642-30487-3}
}

@article{holland2018,
  title = {The {{Dataset Nutrition Label}}: {{A Framework To Drive Higher Data Quality Standards}}},
  shorttitle = {The {{Dataset Nutrition Label}}},
  author = {Holland, Sarah and Hosny, Ahmed and Newman, Sarah and Joseph, Joshua and Chmielinski, Kasia},
  year = {2018},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1805.03677},
  urldate = {2022-11-23},
  abstract = {Artificial intelligence (AI) systems built on incomplete or biased data will often exhibit problematic outcomes. Current methods of data analysis, particularly before model development, are costly and not standardized. The Dataset Nutrition Label (the Label) is a diagnostic framework that lowers the barrier to standardized data analysis by providing a distilled yet comprehensive overview of dataset "ingredients" before AI model development. Building a Label that can be applied across domains and data types requires that the framework itself be flexible and adaptable; as such, the Label is comprised of diverse qualitative and quantitative modules generated through multiple statistical and probabilistic modelling backends, but displayed in a standardized format. To demonstrate and advance this concept, we generated and published an open source prototype with seven sample modules on the ProPublica Dollars for Docs dataset. The benefits of the Label are manyfold. For data specialists, the Label will drive more robust data analysis practices, provide an efficient way to select the best dataset for their purposes, and increase the overall quality of AI models as a result of more robust training datasets and the ability to check for issues at the time of model development. For those building and publishing datasets, the Label creates an expectation of explanation, which will drive better data collection practices. We also explore the limitations of the Label, including the challenges of generalizing across diverse datasets, and the risk of using "ground truth" data as a comparison dataset. We discuss ways to move forward given the limitations identified. Lastly, we lay out future directions for the Dataset Nutrition Label project, including research and public policy agendas to further advance consideration of the concept.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Computers and Society (cs.CY),Databases (cs.DB),FOS: Computer and information sciences}
}

@article{kezar2002,
  title = {Reconstructing {{Static Images}} of {{Leadership}}: {{An Application}} of {{Positionality Theory}}},
  shorttitle = {Reconstructing {{Static Images}} of {{Leadership}}},
  author = {Kezar, Adrianna},
  year = {2002},
  month = feb,
  journal = {Journal of Leadership Studies},
  volume = {8},
  number = {3},
  pages = {94--109},
  issn = {1071-7919},
  doi = {10.1177/107179190200800308},
  urldate = {2022-11-23},
  langid = {english}
}

@article{leonelli2021,
  title = {Data {{Science}} in {{Times}} of {{Pan}}(Dem)Ic},
  author = {Leonelli, Sabina},
  year = {2021},
  month = jan,
  journal = {Harvard Data Science Review},
  doi = {10.1162/99608f92.fbb1bdd6},
  urldate = {2022-11-20},
  langid = {english},
  file = {/Users/cfischer/Zotero/storage/FAVEJ2ET/Leonelli - 2021 - Data Science in Times of Pan(dem)ic.pdf}
}

@article{leslie2020a,
  title = {Tackling {{COVID-19}} through {{Responsible AI Innovation}}: {{Five Steps}} in the {{Right Direction}}},
  shorttitle = {Tackling {{COVID-19}} through {{Responsible AI Innovation}}},
  author = {Leslie, David},
  year = {2020},
  month = jun,
  journal = {Harvard Data Science Review},
  doi = {10.1162/99608f92.4bb9d7a7},
  urldate = {2022-11-20},
  langid = {english},
  file = {/Users/cfischer/Zotero/storage/HG2RTDEL/Leslie - 2020 - Tackling COVID-19 through Responsible AI Innovatio.pdf}
}

@article{lesliedavid2022,
  title = {Data {{Justice}} in {{Practice}}: {{A Guide}} for {{Developers}}},
  shorttitle = {Data {{Justice}} in {{Practice}}},
  author = {Leslie, David and Katell, Michael and Aitken, Mhairi and Singh, Jatinder and Briggs, Morgan and Powell, Rosamund and Rinc{\'o}n, Cami and Perini, Antonella and Jayadeva, Smera and Burr, Christopher},
  year = {2022},
  month = mar,
  publisher = {{Zenodo}},
  doi = {10.5281/ZENODO.6428185},
  urldate = {2022-11-23},
  abstract = {The Advancing Data Justice Research and Practice project aims to broaden understanding of the social, historical, cultural, political, and economic forces that contribute to discrimination and inequity in contemporary ecologies of data collection, governance, and use. This is the consultation draft of a guide for developers and organisations, which are producing, procuring, or using data-intensive technologies. It provides actionable information for those who wish to implement the principles and priorities of data justice in their data practices and within their data innovation ecosystems. In the first section, we introduce the nascent field of data justice, from its early discussions to more recent proposals to relocate understandings of what data justice means. This section includes an account of the outreach we conducted with stakeholders throughout the world in developing a nuanced and pluralistic conception of data justice and concludes with a description of the six pillars of data justice around which this guidance revolves. Next, to support developers in designing, developing, and deploying responsible and equitable data-intensive and AI/ML systems, we outline the AI/ML project lifecycle through a sociotechnical lens, walking the reader through each phase and noting the ethics and governance considerations that should occur at each step of the way. This portion of the guide is intended to provide a background picture of the different stages of the lifecycle and to show how the data justice pillars can be woven into the stages and their respective sociotechnical considerations. To support the operationalisation data justice throughout the entirety of the AI/ML lifecycle and within data innovation ecosystems, we then present five overarching principles of responsible, equitable, and trustworthy data research and innovation practices, the SAFE-D principles\textemdash Safety, Accountability, Fairness, Explainability, and Data Quality, Integrity, Protection, and Privacy. These principles support and underwrite the advancement of data justice within research and innovation practices. We elaborate upon them as high-level goals that are then followed by further specification through the presentation of additional properties, which are to be established in either the project or the system to ensure these goals are reached. Depending on their contexts, potential impacts, and scale, data innovation activities should be carried out in a way that involves different degrees of stakeholder engagement. To facilitate this process, the next section provides an explainer of the Stakeholder Engagement Process and the steps it includes\textemdash preliminary horizon scanning, project scoping and stakeholder analysis, positionality reflection, and establishing stakeholder engagement objectives and methods. Finally, the last section presents guiding questions that will help developers both address data justice issues throughout the AI/ML lifecycle and engage in reflective innovation practices that ensure the design, development, and deployment of responsible and equitable data-intensive and AI/ML systems. This is done by presenting questions related to both the six pillars of data justice and the SAFE-D principles introduced previously.},
  copyright = {Creative Commons Attribution 4.0 International, Open Access},
  keywords = {access,AI ethics,data colonialism,data ethics,data feminism,data justice,data power,decolonial AI,design justice,digital infrastructure,digital rights,economic justice,equity,human rights,intercultural communication,intercultural ethics,knowledge,participation,pluriverse,post-development theory,power,social justice}
}

@book{martin2022,
  title = {Ethics of {{Data}} and {{Analytics}}: {{Concepts}} and {{Cases}}},
  shorttitle = {Ethics of {{Data}} and {{Analytics}}},
  author = {Martin, Kirsten},
  year = {2022},
  month = mar,
  edition = {First},
  publisher = {{Auerbach Publications}},
  address = {{Boca Raton}},
  doi = {10.1201/9781003278290},
  urldate = {2022-11-20},
  isbn = {978-1-00-327829-0},
  langid = {english}
}

@article{mbaye2019,
  title = {Who Is Telling the Story? {{A}} Systematic Review of Authorship for Infectious Disease Research Conducted in {{Africa}}, 1980\textendash 2016},
  shorttitle = {Who Is Telling the Story?},
  author = {Mbaye, Rose and Gebeyehu, Redeat and Hossmann, Stefanie and Mbarga, Nicole and {Bih-Neh}, Estella and Eteki, Lucrece and Thelma, Ohene-Agyei and Oyerinde, Abiodun and Kiti, Gift and Mburu, Yvonne and Haberer, Jessica and Siedner, Mark and Okeke, Iruka and Boum, Yap},
  year = {2019},
  month = oct,
  journal = {BMJ Global Health},
  volume = {4},
  number = {5},
  pages = {e001855},
  issn = {2059-7908},
  doi = {10.1136/bmjgh-2019-001855},
  urldate = {2022-11-20},
  abstract = {Introduction               Africa contributes little to the biomedical literature despite its high burden of infectious diseases. Global health research partnerships aimed at addressing Africa-endemic disease may be polarised. Therefore, we assessed the contribution of researchers in Africa to research on six infectious diseases.                                         Methods               We reviewed publications on HIV and malaria (2013\textendash 2016), tuberculosis (2014\textendash 2016), salmonellosis, Ebola haemorrhagic fever and Buruli ulcer disease (1980\textendash 2016) conducted in Africa and indexed in the PubMed database using Preferred Reporting Items for Systematic Reviews and Meta-Analyses protocol. Papers reporting original research done in Africa with at least one laboratory test performed on biological samples were included. We studied African author proportion and placement per study type, disease, funding, study country and lingua franca.                                         Results               We included 1182 of 2871 retrieved articles that met the inclusion criteria. Of these, 1109 (93.2\%) had at least one Africa-based author, 552 (49.8\%) had an African first author and 41.3\% (n=458) an African last author. Papers on salmonellosis and tuberculosis had a higher proportion of African last authors (p{$<$}0.001) compared with the other diseases. Most of African first and last authors had an affiliation from an Anglophone country. HIV, malaria, tuberculosis and Ebola had the most extramurally funded studies ({$\geq$}70\%), but less than 10\% of the acknowledged funding was from an African funder.                                         Conclusion               African researchers are under-represented in first and last authorship positions in papers published from research done in Africa. This calls for greater investment in capacity building and equitable research partnerships at every level of the global health community.},
  langid = {english},
  file = {/Users/cfischer/Zotero/storage/Y9LHX2YD/Mbaye et al. - 2019 - Who is telling the story A systematic review of a.pdf}
}

@article{merriam2001,
  title = {Power and Positionality: Negotiating Insider/Outsider Status within and across Cultures},
  shorttitle = {Power and Positionality},
  author = {Merriam, Sharan B. and {Johnson-Bailey}, Juanita and Lee, Ming-Yeh and Kee, Youngwha and Ntseane, Gabo and Muhamad, Mazanah},
  year = {2001},
  month = sep,
  journal = {International Journal of Lifelong Education},
  volume = {20},
  number = {5},
  pages = {405--416},
  issn = {0260-1370, 1464-519X},
  doi = {10.1080/02601370120490},
  urldate = {2022-11-23},
  langid = {english}
}

@book{nissenbaum2009,
  title = {Privacy in {{Context}}: {{Technology}}, {{Policy}}, and the {{Integrity}} of {{Social Life}}},
  shorttitle = {Privacy in {{Context}}},
  author = {Nissenbaum, Helen},
  year = {2009},
  month = jan,
  publisher = {{Stanford University Press}},
  doi = {10.1515/9780804772891},
  urldate = {2022-11-20},
  isbn = {978-0-8047-7289-1}
}

@book{nixon2013,
  title = {Slow Violence and the Environmentalism of the Poor},
  author = {Nixon, Rob},
  year = {2013},
  edition = {First Harvard University Press paperback edition},
  publisher = {{Harvard University Press}},
  address = {{Cambridge, Massachusetts London, England}},
  isbn = {978-0-674-07234-3 978-0-674-04930-7},
  langid = {english}
}

@article{obermeyer2019a,
  title = {Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations},
  author = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  year = {2019},
  month = oct,
  journal = {Science},
  volume = {366},
  number = {6464},
  pages = {447--453},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aax2342},
  urldate = {2022-11-20},
  abstract = {Racial bias in health algorithms                            The U.S. health care system uses commercial algorithms to guide health decisions. Obermeyer               et al.               find evidence of racial bias in one widely used algorithm, such that Black patients assigned the same level of risk by the algorithm are sicker than White patients (see the Perspective by Benjamin). The authors estimated that this racial bias reduces the number of Black patients identified for extra care by more than half. Bias occurs because the algorithm uses health costs as a proxy for health needs. Less money is spent on Black patients who have the same level of need, and the algorithm thus falsely concludes that Black patients are healthier than equally sick White patients. Reformulating the algorithm so that it no longer uses costs as a proxy for needs eliminates the racial bias in predicting who needs extra care.                                         Science               , this issue p.               447               ; see also p.               421                        ,              A health algorithm that uses health costs as a proxy for health needs leads to racial bias against Black patients.           ,              Health systems rely on commercial prediction algorithms to identify and help patients with complex health needs. We show that a widely used algorithm, typical of this industry-wide approach and affecting millions of patients, exhibits significant racial bias: At a given risk score, Black patients are considerably sicker than White patients, as evidenced by signs of uncontrolled illnesses. Remedying this disparity would increase the percentage of Black patients receiving additional help from 17.7 to 46.5\%. The bias arises because the algorithm predicts health care costs rather than illness, but unequal access to care means that we spend less money caring for Black patients than for White patients. Thus, despite health care cost appearing to be an effective proxy for health by some measures of predictive accuracy, large racial biases arise. We suggest that the choice of convenient, seemingly effective proxies for ground truth can be an important source of algorithmic bias in many contexts.},
  langid = {english},
  file = {/Users/cfischer/Zotero/storage/4I6M68PR/Obermeyer et al. - 2019 - Dissecting racial bias in an algorithm used to man.pdf}
}

@book{rachels2019,
  title = {The Elements of Moral Philosophy},
  author = {Rachels, Stuart and Rachels, James},
  year = {2019},
  edition = {Ninth edition},
  publisher = {{McGraw-Hill Education}},
  address = {{New York, NY}},
  isbn = {978-1-259-91425-6},
  langid = {english},
  annotation = {OCLC: 1019837277}
}

@book{rachels2023,
  title = {The Elements of Moral Philosophy},
  author = {Rachels, Stuart and Rachels, James},
  year = {2023},
  edition = {Tenth edition},
  publisher = {{McGraw Hill LLC}},
  address = {{Dubuque}},
  abstract = {"Moral philosophy is the study of what morality is and what it requires of us. As Socrates said, it's about "how we ought to live"-and why. It would be helpful if we could begin with a simple, uncontroversial definition of what morality is. Unfortunately, we cannot. There are many rival theories, each expounding a different conception of what it means to live morally, and any definition that goes beyond Socrates's simple formula-tion is bound to offend at least one of them. This should make us cautious, but it need not paralyze us. In this chapter, I will describe the "minimum conception" of morality"--},
  isbn = {978-1-264-99791-6 978-1-264-99869-2},
  lccn = {BJ1012},
  keywords = {Ethics,Textbooks}
}

@book{sangiovanni2017,
  title = {Humanity without {{Dignity}}: {{Moral Equality}}, {{Respect}}, and {{Human Rights}}},
  shorttitle = {Humanity without {{Dignity}}},
  author = {Sangiovanni, Andrea},
  year = {2017},
  month = jun,
  publisher = {{Harvard University Press}},
  doi = {10.4159/9780674977440},
  urldate = {2022-11-22},
  isbn = {978-0-674-97744-0}
}

@incollection{sep-consequentialism,
  title = {Consequentialism},
  booktitle = {The {{Stanford}} Encyclopedia of Philosophy},
  author = {{Sinnott-Armstrong}, Walter},
  editor = {Zalta, Edward N.},
  year = {2021},
  edition = {Fall 2021},
  publisher = {{Metaphysics Research Lab, Stanford University}}
}

@incollection{sep-ethics-virtue,
  title = {Virtue Ethics},
  booktitle = {The {{Stanford}} Encyclopedia of Philosophy},
  author = {Hursthouse, Rosalind and Pettigrove, Glen},
  editor = {Zalta, Edward N.},
  year = {2018},
  edition = {Winter 2018},
  publisher = {{Metaphysics Research Lab, Stanford University}}
}

@article{shrum2005,
  title = {Reagency of the {{Internet}}, or, {{How I Became}} a {{Guest}} for {{Science}}},
  author = {Shrum, Wesley},
  year = {2005},
  month = oct,
  journal = {Social Studies of Science},
  volume = {35},
  number = {5},
  pages = {723--754},
  issn = {0306-3127, 1460-3659},
  doi = {10.1177/0306312705052106},
  urldate = {2022-11-20},
  abstract = {This essay is a call for research on the role of information and communication technology in distant lands. I address the globalization of science as a process by replacing the concept of development with the idea of reagency, a process of redirection involving a contingent reaction between identities. I focus on the Guest, an identity that assumes particular importance in relation to Hosts in Africa, Latin America, and Asia. Following recent work that stresses the dependence of knowledge production on places, the Guest House is introduced as an architectural structure that crystallizes and reinforces a Guest/Host relationship that has developed during the aid era. The advent of the Internet offers the possibility of a change in the structure of science, with the inclusion of researchers in distant lands as full participants in global scientific communities. The principal issue is whether the connectivity initiative centering on the Internet is just another development program, like so many others that have come and gone, or whether it is different in character. Three empirical research questions are posed to assist in examining this question. A minor thread throughout the essay explains the author's romantic interest in the subject, and his transition from a phony donor to a real one.},
  langid = {english}
}

@article{tritter2006,
  title = {The Snakes and Ladders of User Involvement: {{Moving}} beyond {{Arnstein}}},
  shorttitle = {The Snakes and Ladders of User Involvement},
  author = {Tritter, Jonathan Quetzal and McCallum, Alison},
  year = {2006},
  month = apr,
  journal = {Health Policy},
  volume = {76},
  number = {2},
  pages = {156--168},
  issn = {01688510},
  doi = {10.1016/j.healthpol.2005.05.008},
  urldate = {2022-11-23},
  langid = {english}
}

@phdthesis{vandenberghe2022,
  title = {The Influence of Fairness and Ethical Trade-Offs on Public Support for Road Safety Measures. {{An}} International and Intercultural Exploration},
  author = {{Van den Berghe}, Wouter},
  year = {2022},
  school = {UCL (University College London)}
}

@incollection{vlastos1984,
  title = {Justice and {{Equality}}},
  booktitle = {Equality: {{Selected Readings}}},
  author = {Vlastos, Gregory},
  year = {1984}
}

@article{weinhardt2020,
  title = {Ethische {{Fragen}} Bei Der {{Nutzung}} von {{Big Data}} in Der {{SozialforschungEthical Issues}} in the {{Use}} of {{Big Data}} for {{Social Research}}},
  author = {Weinhardt, Michael},
  year = {2020},
  journal = {{$<$}p{$>$}Historical Social Research / Historische Sozialforschung Vol. 45},
  volume = {No. 3},
  pages = {Volumes per year: 1{$<$}/p{$>$}},
  publisher = {{GESIS - Leibniz-Institut f\"ur Sozialwissenschaften}},
  issn = {0172-6404},
  doi = {10.12759/HSR.45.2020.3.342-368},
  urldate = {2022-11-23},
  abstract = {With the advent of Big Data (BD) in the social sciences, vast amounts of data (and the tools to analyze them) have become available faster than ethical and legal standards could develop regarding the use of such data. At the same time, data collectors and analysts face new moral dilemmas as the proliferation of personal and impersonal data clearly poses new challenges to traditional assumptions about privacy and autonomy. The discussion of such ethical challenges seems to lag behind and the literature specifically dealing with the research ethics of BD is still scarce. This article asks which ethical and legal aspects need to be considered when collecting and analyzing data on individuals from the web and combining them to gain an enriched picture of human activities. It proceeds to provide a brief overview of existing research ethics regulations and outlines areas of particular relevance to the challenges that come with the use of BD, such as the delineation of human subject research, the (im)possibility of informed consent for these new kinds of data, the sources and public availability of data and questions of risk and risk assessment. It also formulates some generic recommendations in order to stimulate further debate, one of which posits that social scientists must address and discuss the challenges that emerge in research applications of BD more widely than it is currently the case.},
  collaborator = {{GESIS-Leibniz-Institut F{\"u}r Sozialwissenschaften}},
  copyright = {Creative Commons Attribution 4.0 International},
  langid = {english}
}

@book{worldhealthorganization2022,
  title = {Report of the {{WHO}} Global Technical Consultation on Public Health and Social Measures during Health Emergencies: Online Meeting, 31 {{August}} to 2 {{September}} 2021},
  shorttitle = {Report of the {{WHO}} Global Technical Consultation on Public Health and Social Measures during Health Emergencies},
  author = {{World Health Organization}},
  year = {2022},
  publisher = {{World Health Organization}},
  address = {{Geneva}},
  urldate = {2022-11-20},
  isbn = {978-92-4-004321-3},
  langid = {english},
  keywords = {{Disease Transmission, Infectious},Emergencies,Meeting Abstract,prevention and control,Public Health,Social Factors},
  file = {/Users/cfischer/Zotero/storage/FBCAIFHT/World Health Organization - 2022 - Report of the WHO global technical consultation on.pdf}
}
