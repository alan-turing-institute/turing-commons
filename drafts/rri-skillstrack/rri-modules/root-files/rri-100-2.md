---
slideOptions:
  transition: slide
  spotlight:
    enabled: true
---

# What is Responsible Research and Innovation? (Section 2) Collective and Distributed Responsibility

> **Note**
> The following sections are also part of this module:
>
> - Section 1: [Understanding Responsibility](rri-100-1.md)
> - Section 2: [Collective and Distributed Responsibility](rri-100-2.md)
> - Section 3: [Defining Responsible Research and Innovation](rri-100-3.md)
> - Section 4: [The Scope and Horizon of Responsibility](rri-100-4.md)

---

## The Problem of Many Hands

<!-- Reflective Question -->

How should we assign moral responsibility when large groups of people, organized or unorganized, wrongfully cause some harm?

----

This is not just an abstract challenge for moral philosophers. It is known as the 'Problem of Many Hands' and affects areas including:

- Anthropogenic Climate Change
- Medical Negligence
- Public Policy and Governance

---

## Collective Responsibility

One response to the problem of many hands is to ascribe "collective responsibility" to groups of people or organisations.

<!-- Admonition -->

Collective responsibility, here, is not the same as mechanisms of legal accountability that are used to fine organisations (e.g. limited liability companies).

<!-- Admonition -->

Whether we can ascribe collective responsibility is independent from any practical consequence (e.g. fines, sanctions). Here, we are just interested in whether it makes sense, conceptually, to blame a collective.

----

### Arguments *For* Collective Responsibility

In large-scale data science and AI projects, the distributed structure of roles and responsibilities is necessary for various reasons:

- Individuals have specific forms of expertise, and the delivery of a fully functional AI system requires a plurality of skills. 
- Reuse of datasets is common, and the collection and curation of the original dataset may not have been performed by the software engineer responsible for training a model. 
- Pre-trained models and cloud computing services are increasingly common (e.g. AI as a service, APIs), such that project teams are reliant on third-party infrastructure.

----

As such, when we ask where responsibility for the behaviour of an AI system lies (e.g. responsibility for biased or discriminatory inferences), it is incredibly difficult to locate it at an individualistic level of abstraction because of the distributed nature of the system's development. 
Rather, it seems best located at the level of a project team or organisation (i.e. collective and distributed responsibility).

----

<!-- Reflective Question -->

If moral praise and blame is only directed at moral agents, does this make companies or organisations moral agents?

----

### Arguments *Against* Collective Responsibility


Holding a group collectively responsible can have pragmatic benefits (e.g. punishing a group for the misbehaviour of an individual creates motivating disincentives for future misconduct). 
However, our intuitions may still lead us to think that only one person was truly *responsible*.

----
Beyond our individual intuitions, there are different arguments to oppose the notion of collective responsibility. 

Some of the arguments go against the very idea of collective responsibility make sense as a moral concept, while others are normative arguments against the value of ascribing collective moral responsbility.

----

Does it make sense conceptually to hold a group itself (as opposed to its individual members) morally responsible?

Some people have argued that it not possible for groups themselves to cause harm in the way that is required in order to ascribe them moral responsibility. 
The idea is that in order to place blame on someone, they need to have acted in a certain way with particular intentions. The claim of those sceptic to collective responsibility, is that groups cannot form intentions, and thus cannot cause harm to others _as groups_.

The argument can get quite technical, but they general idea behind it is that groups (as opposed to individuals) are simply not the _kinds of agents_ who can be held responsible for their actions.[^sep_cr]

----

The following quote by philosopher H. D. Lewis sums up a version of this view quite clearly:

> "Value belongs to the individual and it is the individual who is the sole bearer of moral responsibility. No one is morally guilty except in relation to some conduct which he himself considered to be wrong... Collective responsibility is... barbarous." (Lewis 1948, pp. 3–6)[^lewis]

----

On the other hand, arguments against collective responsibility can be based on normative considerations, rather than metaphysical ones.

All this means is that the core of the argument is not focused on unpacking the concept of moral responsibility and whether it holds as an idea in and of itself, but rather on the value of ascribing collective responsibility to groups. 
In particular, some argue that holding groups responsible can have negative consequences in how we place blame on others in ways that can be unfair.

---- 

For example, it can be argued that collective responsibility lets individuals off the hook for personal responsbility. 
For instance, consider the phenomena of the 'bystander effect', explained in the following video:

<iframe width="560" height="315" src="https://www.youtube.com/embed/OSsPfbup0ac?start=35" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

The idea is that when we hold a group responsible for an action, this inevitable 'waters-down' any individual responsibility for said action.

<!-- Admonition -->
<!-- Reflective question -->
- What do you think about this?
- Does it make sense to distribute collective responsibility?
- Does distributing responsibility invariably lead to minisiming individual responsibility?
- Are there any cases where you think this does not hold?
<!-- End admonition -->

----

Those who wish to argue against collective notions of responsibility, therefore, may wish to appeal to intuitions or point to such empiricial matter.
However, defendants of collective responsibility could respond that the failure is a conceptual issue. 
That is, an inability to adequately and precisely specify particular types of responsibility. 

For instance, in the context of a data science or AI project, while we may not be able to locate responsibility for the overall behaviour, we can identify specific forms of individual responsibility:

- Responsibility for transparent documentation of data provenance
- Responsibility for due diligence when reusuing existing artefacts (e.g. datasets, pre-trained models)
- Responsibility for carrying out thorough risk assessments
- Responsibility for organising meaningful forms or stakeholder engagement

----

<!-- Reflective Question -->

What do you think? Is collective responsibility a coherent concept? Or should we make do with structured forms of individual responsibility?

---

## One More Thing: The Replicability Crisis

Philosopher of Science, Sabina Leonelli, has argued that the replicability crisis is evidence of the challenge of locating moral responsibility and professional accountability within large-scale research projects:

> "The recent ‘replicability crisis’ in psychology and biomedicine, which many perceive as evidencing an overwhelming lack of research integrity and a failure of peer review, could also be interpreted as illustrating the difficulties in making individuals accountable for their data processing actions within large research networks—which in turn generates problems when attempting to reconstruct, describe and evaluate the methods and assumptions made in any one piece of research." > (Leonelli, 2016)

---

[^sep_cr]: Add reference for SEP article on CR.
[^lewis]: Add reference for Lewis, 1948.
