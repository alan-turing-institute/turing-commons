---
slideOptions:
  transition: slide
  spotlight:
    enabled: true
---

# Fairness (Section 4): Practical Fairness

> **Note**
> The following sections are part of this module:
>
> - Section 1: [What is Fairness?](rri-203-1.md)
> - Section 2: [Sociocultural Fairness](rri-203-2.md)
> - Section 3: [Statistical Fairness](rri-203-3.md)
> - Section 4: [Practical Fairness](rri-203-4.md)

---

In the previous two sections, we explored theoretical and conceptual topics related to sociocultural and statistical fairness. In this section, we will bring these topics together to look at practical means for ensuring fairness across the project lifecycle.

We will look at two central topics, which have a firm foothold in fair machine learning and AI research and development:

1. Bias Mitigation
2. Stakeholder Engagement and Participatory Design

<!-- start admonition -->

Both of these topics are covered in further detail in other skills tracks and modules, and there are also specific tools that we have developed to help individuals and teams enact the recommendations within this section:

- ~~Bias Self-Assessment Tool~~ (Coming Soon)
- ~~Stakeholder Engagement Process Plan~~ (Coming Soon)

<!-- end admonition -->

## Identifying and Mitigating Bias

You may have heard about biased algorithms or AI systems, which can cause harm to individuals or groups of people.
For example, perhaps you have heard about biased algorithms used in hiring or recruitment, which can discriminate against certain groups of people and make it comparatively harder for them to get a job.[^amazon]
Or, perhaps you have heard about biased machine learning systems that learn discriminatory patterns from the healthcare data they are trained on, resulting in unfair decisions being made about certain groups of patients.[^obermeyer]

## Types of Bias

There are three types of bias that we will consider:

1. Social Bias
2. Statistical Bias
3. Cognitive Bias

---

## Social Biases

> Social biases are processes, structures, beliefs, or ideas that have a discriminatory impact upon a group of people.

----

### Examples of Social Biases

- Association of a default gender with specific jobs or professions (e.g. female nurses; male doctors).
- Transport infrastructure that favours non-disabled individuals, and creates a comparative disadvantage for people with disabilities (e.g. wheelchair users).
- Historical patterns of inequality that disproportionately impact vulnerable or marginalised groups (e.g. those from lower socioeconomic backgrounds) and make it harder for those individuals to achieve the same outcomes as others.

---

## Statistical Biases

> "A systematic distortion, due to a design problem, an interfering factor, or a judgement, that can affect the conception, design, or conduct of a study, or the collection, analysis, interpretation, presentation, or discussion of outcome data, causing erroneous overestimation or underestimation of the probable size of an effect or association" ([Aronson, 2022](https://catalogofbias.org/2018/06/15/a-word-about-evidence-6-bias-a-proposed-definition/)).

----

### Examples of Statistical Biases

- Missing Data Bias: missingness can lead to inaccurate inferences being made about the underlying data generating processes and affect the validity of a predictive model when the missing data belong disproportionatley to a specific sub-group in the dataset.
- Label Bias: occurs when a label (or feature) within a dataset does not mean the same thing for all data subjects (e.g. emotional states used as "ground truth" labels in a dataset of faces).
- Training-Serving Skew: occurs when a model is used to predict states or classify subjects or objects whose data are not similar to or representative of the individuals or objects whose data were used to train, test, and validate the model.

---

## Cognitive Biases

> A tendency or predisposition for a person to form a judgement, recall information, or make a decision on the basis of a (potentially adaptive) heuristic, which in certain contexts can lead to the deviation from a proposed norm of rationality (e.g. logical reasoning).

----

#### Examples of Cognitive Biases

- Confirmation Bias: Confirmation biases arise from tendencies to search for, gather, or use information that confirms pre-existing ideas and beliefs, and to dismiss or downplay the significance of information that disconfirms one’s favoured hypothesis. This can be the result of motivated reasoning or sub-conscious attitudes, which in turn may lead to prejudicial judgements that are not based on reasoned evidence.
- Availability Bias: The tendency to make judgements or decisions based on the information that is most readily available (e.g., more easily recalled). When this information is recalled on multiple occasions, the bias can be reinforced through repetition—known as a ‘cascade’.
- Naive Realism: a disposition to perceive the world in objective terms that can inhibit recognition of socially constructed categories. For instance, treating ‘employability’ as something that is objectively measurable and, therefore, able to be predicted by a machine learning algorithm on the basis of objective factors (e.g., exam grades, educational attainment).

---

## Situating Bias Across the Sociotechnical Lifecycle

<!-- Explain how bias enters into and is exacerbated across the sociotechnical lifecycle -->

> Should we be building these systems at all?

----

[^amazon]: add reference to Amazon hiring tool
[^obermeyer]: add reference to obermeyer paper (https://www.science.org/doi/10.1126/science.aax2342)