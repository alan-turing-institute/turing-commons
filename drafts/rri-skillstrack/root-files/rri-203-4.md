---
slideOptions:
  transition: slide
  spotlight:
    enabled: true
---

# Fairness (Section 4): Practical Fairness

> **Note**
> The following sections are part of this module:
>
> - Section 1: [What is Fairness?](rri-203-1.md)
> - Section 2: [Sociocultural Fairness](rri-203-2.md)
> - Section 3: [Statistical Fairness](rri-203-3.md)
> - Section 4: [Practical Fairness](rri-203-4.md)

---

<!-- this whole section will be about proceduralising and operationalising fairness using partials from a case study -->

## Types of Bias

There are three types of bias that we will consider:

1. Social Bias
2. Statistical Bias
3. Cognitive Bias

---

## Social Biases

> Social biases are processes, structures, beliefs, or ideas that have a discriminatory impact upon a group of people.

----

### Examples of Social Biases

- Association of a default gender with specific jobs or professions (e.g. female nurses; male doctors).
- Transport infrastructure that favours non-disabled individuals, and creates a comparative disadvantage for people with disabilities (e.g. wheelchair users).
- Historical patterns of inequality that disproportionately impact vulnerable or marginalised groups (e.g. those from lower socioeconomic backgrounds) and make it harder for those individuals to achieve the same outcomes as others.

---

## Statistical Biases

> "A systematic distortion, due to a design problem, an interfering factor, or a judgement, that can affect the conception, design, or conduct of a study, or the collection, analysis, interpretation, presentation, or discussion of outcome data, causing erroneous overestimation or underestimation of the probable size of an effect or association" ([Aronson, 2022](https://catalogofbias.org/2018/06/15/a-word-about-evidence-6-bias-a-proposed-definition/)).

----

### Examples of Statistical Biases

- Missing Data Bias: missingness can lead to inaccurate inferences being made about the underlying data generating processes and affect the validity of a predictive model when the missing data belong disproportionatley to a specific sub-group in the dataset.
- Label Bias: occurs when a label (or feature) within a dataset does not mean the same thing for all data subjects (e.g. emotional states used as "ground truth" labels in a dataset of faces).
- Training-Serving Skew: occurs when a model is used to predict states or classify subjects or objects whose data are not similar to or representative of the individuals or objects whose data were used to train, test, and validate the model.

---

## Cognitive Biases

> A tendency or predisposition for a person to form a judgement, recall information, or make a decision on the basis of a (potentially adaptive) heuristic, which in certain contexts can lead to the deviation from a proposed norm of rationality (e.g. logical reasoning).

----

#### Examples of Cognitive Biases

- Confirmation Bias: Confirmation biases arise from tendencies to search for, gather, or use information that confirms pre-existing ideas and beliefs, and to dismiss or downplay the significance of information that disconfirms one’s favoured hypothesis. This can be the result of motivated reasoning or sub-conscious attitudes, which in turn may lead to prejudicial judgements that are not based on reasoned evidence.
- Availability Bias: The tendency to make judgements or decisions based on the information that is most readily available (e.g., more easily recalled). When this information is recalled on multiple occasions, the bias can be reinforced through repetition—known as a ‘cascade’.
- Naive Realism: a disposition to perceive the world in objective terms that can inhibit recognition of socially constructed categories. For instance, treating ‘employability’ as something that is objectively measurable and, therefore, able to be predicted by a machine learning algorithm on the basis of objective factors (e.g., exam grades, educational attainment).

---

## Situating Bias Across the Sociotechnical Lifecycle

<!-- Explain how bias enters into and is exacerbated across the sociotechnical lifecycle -->

> Should we be building these systems at all?

----
